{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Model Bias using `smclarify`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Amazon Science: _[How Clarify helps machine learning developers detect unintended bias](https://www.amazon.science/latest-news/how-clarify-helps-machine-learning-developers-detect-unintended-bias)_ \n",
    "\n",
    "[<img src=\"img/amazon_science_clarify.png\"  width=\"100%\" align=\"left\">](https://www.amazon.science/latest-news/how-clarify-helps-machine-learning-developers-detect-unintended-bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminology\n",
    "\n",
    "* **Bias**: \n",
    "An imbalance in the training data or the prediction behavior of the model across different groups, such as age or income bracket. Biases can result from the data or algorithm used to train your model. For instance, if an ML model is trained primarily on data from middle-aged individuals, it may be less accurate when making predictions involving younger and older people.\n",
    "\n",
    "* **Bias metric**: \n",
    "A function that returns numerical values indicating the level of a potential bias.\n",
    "\n",
    "* **Bias report**:\n",
    "A collection of bias metrics for a given dataset, or a combination of a dataset and a model.\n",
    "\n",
    "* **Label**:\n",
    "Feature that is the target for training a machine learning model. Referred to as the observed label or observed outcome.\n",
    "\n",
    "* **Positive label values**:\n",
    "Label values that are favorable to a demographic group observed in a sample. In other words, designates a sample as having a positive result.\n",
    "\n",
    "* **Negative label values**:\n",
    "Label values that are unfavorable to a demographic group observed in a sample. In other words, designates a sample as having a negative result.\n",
    "\n",
    "* **Facet**:\n",
    "A column or feature that contains the attributes with respect to which bias is measured.\n",
    "\n",
    "* **Facet value**:\n",
    "The feature values of attributes that bias might favor or disfavor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posttraining Bias Metrics\n",
    "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-measure-post-training-bias.html\n",
    "\n",
    "* **Difference in Positive Proportions in Predicted Labels (DPPL)**:\n",
    "Measures the difference in the proportion of positive predictions between the favored facet a and the disfavored facet d.\n",
    "\n",
    "* **Disparate Impact (DI)**:\n",
    "Measures the ratio of proportions of the predicted labels for the favored facet a and the disfavored facet d.\n",
    "\n",
    "* **Difference in Conditional Acceptance (DCAcc)**:\n",
    "Compares the observed labels to the labels predicted by a model and assesses whether this is the same across facets for predicted positive outcomes (acceptances).\n",
    "\n",
    "* **Difference in Conditional Rejection (DCR)**:\n",
    "Compares the observed labels to the labels predicted by a model and assesses whether this is the same across facets for negative outcomes (rejections).\n",
    "\n",
    "* **Recall Difference (RD)**:\n",
    "Compares the recall of the model for the favored and disfavored facets.\n",
    "\n",
    "* **Difference in Acceptance Rates (DAR)**:\n",
    "Measures the difference in the ratios of the observed positive outcomes (TP) to the predicted positives (TP + FP) between the favored and disfavored facets.\n",
    "\n",
    "* **Difference in Rejection Rates (DRR)**:\n",
    "Measures the difference in the ratios of the observed negative outcomes (TN) to the predicted negatives (TN + FN) between the disfavored and favored facets.\n",
    "\n",
    "* **Accuracy Difference (AD)**:\n",
    "Measures the difference between the prediction accuracy for the favored and disfavored facets.\n",
    "\n",
    "* **Treatment Equality (TE)**:\n",
    "Measures the difference in the ratio of false positives to false negatives between the favored and disfavored facets.\n",
    "\n",
    "* **Conditional Demographic Disparity in Predicted Labels (CDDPL)**:\n",
    "Measures the disparity of predicted labels between the facets as a whole, but also by subgroups.\n",
    "\n",
    "* **Counterfactual Fliptest (FT)**:\n",
    "Examines each member of facet d and assesses whether similar members of facet a have different model predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from smclarify.bias.report import *\n",
    "from smclarify.util.dataset import Datasets, german_lending_readable_values\n",
    "from typing import Dict\n",
    "from collections import defaultdict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test data for bias\n",
    "\n",
    "We created test data in JSONLines format to match the model inputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"star_rating\": [1, 2, 3, 4, 5],\n",
    "    \"review_body\": [\"Worst ever\", \"Expected more\", \"Its ok\", \"I like it\", \"I love it\"],\n",
    "    \"product_category\": [\"Gift Card\", \"Gift Card\", \"Gift Card\", \"Digital_Software\", \"Digital_Software\"],\n",
    "    \"star_rating_predicted\": [1, 2, 3, 4, 5],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   star_rating    review_body  product_category  star_rating_predicted\n",
      "0            1     Worst ever         Gift Card                      1\n",
      "1            2  Expected more         Gift Card                      2\n",
      "2            3         Its ok         Gift Card                      3\n",
      "3            4      I like it  Digital_Software                      4\n",
      "4            5      I love it  Digital_Software                      5\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(data, columns=[\"star_rating\", \"review_body\", \"product_category\", \"star_rating_predicted\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data columns into `categorical` data type required for Clarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['star_rating'] = df['star_rating'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['star_rating_predicted'] = df['star_rating_predicted'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['product_category'] = df['product_category'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure Clarify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "facet_column = FacetColumn(name=\"product_category\", sensitive_values=[\"Gift Card\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_column = LabelColumn(name=\"star_rating\", series=df[\"star_rating\"], positive_label_values=[5, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_label_column = LabelColumn(\n",
    "    name=\"star_rating_predicted\", series=df[\"star_rating_predicted\"], positive_label_values=[5, 4]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_training_report = bias_report(\n",
    "    df=df,\n",
    "    facet_column=facet_column,\n",
    "    label_column=label_column,\n",
    "    stage_type=StageType.POST_TRAINING,\n",
    "    predicted_label_column=predicted_label_column,\n",
    "    metrics=[\"DPPL\", \"DI\", \"DCA\", \"DCR\", \"RD\", \"DAR\", \"DRR\", \"AD\", \"TE\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Post-Training Bias Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'metrics': [{'description': 'Accuracy Difference (AD)',\n",
      "               'name': 'AD',\n",
      "               'value': 0.0},\n",
      "              {'description': 'Difference in Acceptance Rates (DAR)',\n",
      "               'name': 'DAR',\n",
      "               'value': 1.0},\n",
      "              {'description': 'Difference in Conditional Acceptance (DCA)',\n",
      "               'name': 'DCA',\n",
      "               'value': 1.0},\n",
      "              {'description': 'Difference in Conditional Rejection (DCR)',\n",
      "               'name': 'DCR',\n",
      "               'value': 1.0},\n",
      "              {'description': 'Disparate Impact (DI)',\n",
      "               'name': 'DI',\n",
      "               'value': 0.0},\n",
      "              {'description': 'Difference in Positive Proportions in Predicted '\n",
      "                              'Labels (DPPL)',\n",
      "               'name': 'DPPL',\n",
      "               'value': 1.0},\n",
      "              {'description': 'Difference in Rejection Rates (DRR)',\n",
      "               'name': 'DRR',\n",
      "               'value': 1.0},\n",
      "              {'description': 'Recall Difference (RD)',\n",
      "               'name': 'RD',\n",
      "               'value': 1.0},\n",
      "              {'description': 'Treatment Equality (TE)',\n",
      "               'name': 'TE',\n",
      "               'value': 0.0}],\n",
      "  'value_or_threshold': 'Gift Card'}]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "pprint(post_training_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "data_science_on_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
