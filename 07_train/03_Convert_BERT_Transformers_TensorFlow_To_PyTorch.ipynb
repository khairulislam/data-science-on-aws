{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the TensorFlow-Trained BERT Model to a PyTorch Model\n",
    "We do this to show HuggingFace's ability to convert models between TensorFlow and PyTorch.\n",
    "\n",
    "We will subsequently deploy the model as a PyTorch model using the TorchServe Inference Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    training_job_name\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please wait for the Training notebook to finish.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous training_job_name: tensorflow-training-2024-03-03-04-02-13-539\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous training_job_name: {}\".format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the TensorFlow-Trained Model from S3 to this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-211125778552/tensorflow-training-2024-03-03-04-02-13-539/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz $models_dir/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle as pkl\n",
    "\n",
    "try:\n",
    "    tar = tarfile.open(\"{}/model.tar.gz\".format(models_dir))\n",
    "    tar.extractall(path=models_dir)\n",
    "    tar.close()\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] in tar operation: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 888128\n",
      "drwxr-xr-x  8 sagemaker-user users       127 Mar  6 15:38 .\n",
      "drwxr-xr-x 21 sagemaker-user users      4096 Mar  3 05:12 ..\n",
      "drwxr-xr-x  2 sagemaker-user users        26 Mar  3 05:09 code\n",
      "drwxr-xr-x  2 sagemaker-user users        57 Mar  3 05:11 metrics\n",
      "-rw-r--r--  1 sagemaker-user users 909435719 Mar  3 05:11 model.tar.gz\n",
      "drwxr-xr-x  4 sagemaker-user users        37 Mar  3 04:26 tensorboard\n",
      "drwxr-xr-x  3 sagemaker-user users        25 Mar  3 04:04 tensorflow\n",
      "drwxr-xr-x  2 sagemaker-user users        61 Mar  3 05:09 test_data\n",
      "drwxr-xr-x  3 sagemaker-user users        24 Mar  3 04:04 transformers\n"
     ]
    }
   ],
   "source": [
    "!ls -al $models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261688\n",
      "drwxr-xr-x 2 sagemaker-user users        44 Mar  3 05:06 .\n",
      "drwxr-xr-x 3 sagemaker-user users        24 Mar  3 04:04 ..\n",
      "-rw-r--r-- 1 sagemaker-user users       689 Mar  3 05:06 config.json\n",
      "-rw-r--r-- 1 sagemaker-user users 267961728 Mar  3 05:06 tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "transformer_model_dir = \"{}/transformers/fine-tuned/\".format(models_dir)\n",
    "\n",
    "!ls -al $transformer_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": 1,\n",
      "    \"1\": 2,\n",
      "    \"2\": 3,\n",
      "    \"3\": 4,\n",
      "    \"4\": 5\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"1\": 0,\n",
      "    \"2\": 1,\n",
      "    \"3\": 2,\n",
      "    \"4\": 3,\n",
      "    \"5\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.10.0.dev0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat $transformer_model_dir/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the TensorFlow Model to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-06 15:38:29.181713: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory\n",
      "2024-03-06 15:38:29.182223: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-03-06 15:38:34.809963: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2024-03-06 15:38:34.809995: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2024-03-06 15:38:34.810022: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (default): /proc/driver/nvidia/version does not exist\n",
      "2024-03-06 15:38:34.811758: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-06 15:38:34.833841: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2500000000 Hz\n",
      "2024-03-06 15:38:34.834366: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7366d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2024-03-06 15:38:34.834390: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2024-03-06 15:38:34.867765: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "2024-03-06 15:38:34.916213: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-03-06 15:38:35.372585: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-03-06 15:38:35.428333: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-03-06 15:38:39.864904: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-03-06 15:38:39.932684: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification  # PyTorch version\n",
    "\n",
    "try:\n",
    "    loaded_pytorch_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        transformer_model_dir,\n",
    "        id2label={0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n",
    "        label2id={1: 0, 2: 1, 3: 2, 4: 3, 5: 4},\n",
    "        from_tf=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] in loading model {}: \".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.modeling_distilbert.DistilBertForSequenceClassification'>\n",
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (1): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (2): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (3): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (4): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "        (5): TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(type(loaded_pytorch_model))\n",
    "print(loaded_pytorch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Transformer/PyTorch Model with `.save_pretrained()`\n",
    "This will create `pytorch_model.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_models_dir = \"./model/transformers/pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pytorch_model.save_pretrained(pytorch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261596\n",
      "drwxr-xr-x 2 sagemaker-user users        50 Mar  6 15:38 .\n",
      "drwxr-xr-x 4 sagemaker-user users        39 Mar  6 15:38 ..\n",
      "-rw-r--r-- 1 sagemaker-user users       712 Mar  6 15:38 config.json\n",
      "-rw-r--r-- 1 sagemaker-user users 267869890 Mar  6 15:38 pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -al $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = DistilBertForSequenceClassification.from_pretrained(pytorch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261596\n",
      "drwxr-xr-x 2 sagemaker-user users        50 Mar  6 15:38 .\n",
      "drwxr-xr-x 4 sagemaker-user users        39 Mar  6 15:38 ..\n",
      "-rw-r--r-- 1 sagemaker-user users       712 Mar  6 15:38 config.json\n",
      "-rw-r--r-- 1 sagemaker-user users 267869890 Mar  6 15:38 pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -al $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DistilBertForSequenceClassification(\n",
       "  (distilbert): DistilBertModel(\n",
       "    (embeddings): Embeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (transformer): Transformer(\n",
       "      (layer): ModuleList(\n",
       "        (0): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (1): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (2): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (3): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (4): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "        (5): TransformerBlock(\n",
       "          (attention): MultiHeadSelfAttention(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (ffn): FFN(\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "config = DistilBertConfig.from_json_file(\"{}/config.json\".format(pytorch_models_dir))\n",
    "\n",
    "model_path = \"{}/{}\".format(pytorch_models_dir, \"pytorch_model.bin\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 15:38:46.454 default:453 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-03-06 15:38:46.630 default:453 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "input_data: [{\"features\": [\"This is great!\"]},                {\"features\": [\"This is bad.\"]}]\n",
      "data_json: [{'features': ['This is great!']}, {'features': ['This is bad.']}]\n",
      "data_json_line: {'features': ['This is great!']}\n",
      "type(data_json_line): <class 'dict'>\n",
      "review_body: This is great!\n",
      "output: (tensor([[ 0.0913, -0.0083, -0.1442, -0.0366,  0.0816]],\n",
      "       grad_fn=<AddmmBackward>),)\n",
      "softmax_output: tensor([[0.2190, 0.1983, 0.1731, 0.1927, 0.2169]], grad_fn=<SoftmaxBackward>)\n",
      "predicted_class: 1\n",
      "data_json_line: {'features': ['This is bad.']}\n",
      "type(data_json_line): <class 'dict'>\n",
      "review_body: This is bad.\n",
      "output: (tensor([[ 0.0363,  0.0183, -0.0332, -0.0609,  0.0948]],\n",
      "       grad_fn=<AddmmBackward>),)\n",
      "softmax_output: tensor([[0.2048, 0.2012, 0.1911, 0.1858, 0.2171]], grad_fn=<SoftmaxBackward>)\n",
      "predicted_class: 5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import smdebug.pytorch as smd\n",
    "from torch import nn\n",
    "\n",
    "max_seq_length = 64\n",
    "classes = [1, 2, 3, 4, 5]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "input_data = '[{\"features\": [\"This is great!\"]}, \\\n",
    "               {\"features\": [\"This is bad.\"]}]'\n",
    "print(\"input_data: {}\".format(input_data))\n",
    "\n",
    "data_json = json.loads(input_data)\n",
    "print(\"data_json: {}\".format(data_json))\n",
    "\n",
    "predicted_classes = []\n",
    "save_config = smd.SaveConfig(save_interval=1)\n",
    "# hook = smd.Hook(\"/tmp/tensors\", save_config=save_config, include_regex='.*')\n",
    "\n",
    "# hook.register_module(model)\n",
    "\n",
    "for data_json_line in data_json:\n",
    "    print(\"data_json_line: {}\".format(data_json_line))\n",
    "    print(\"type(data_json_line): {}\".format(type(data_json_line)))\n",
    "\n",
    "    review_body = data_json_line[\"features\"][0]\n",
    "    print(\"\"\"review_body: {}\"\"\".format(review_body))\n",
    "\n",
    "    encode_plus_token = tokenizer.encode_plus(\n",
    "        review_body,\n",
    "        max_length=max_seq_length,\n",
    "        add_special_tokens=False,\n",
    "        #        return_token_type_ids=False,\n",
    "        return_token_type_ids=None,\n",
    "        #        pad_to_max_length=True,\n",
    "        padding=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    input_ids = encode_plus_token[\"input_ids\"]\n",
    "\n",
    "    #    hook._write_raw_tensor_simple(\"input_tokens\", tokenizer.tokenize(review_body))\n",
    "    attention_mask = encode_plus_token[\"attention_mask\"]\n",
    "\n",
    "    output = model(input_ids, attention_mask)\n",
    "    print(\"output: {}\".format(output))\n",
    "\n",
    "    softmax_fn = nn.Softmax(dim=1)\n",
    "    softmax_output = softmax_fn(output[0])\n",
    "    print(\"softmax_output: {}\".format(softmax_output))\n",
    "\n",
    "    _, prediction = torch.max(softmax_output, dim=1)\n",
    "\n",
    "    predicted_class_idx = prediction.item()\n",
    "    predicted_class = classes[predicted_class_idx]\n",
    "    print(\"predicted_class: {}\".format(predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Transformer/PyTorch Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/model/tensorflow-training-2024-03-03-04-02-13-539/transformer-pytorch/\n"
     ]
    }
   ],
   "source": [
    "transformer_pytorch_model_dir_s3_uri = \"s3://{}/model/{}/transformer-pytorch/\".format(bucket, training_job_name)\n",
    "print(transformer_pytorch_model_dir_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./model/transformers/pytorch/pytorch_model.bin ./model/transformers/pytorch/model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "model.pth\n"
     ]
    }
   ],
   "source": [
    "!cd ./model/transformers/pytorch/ && tar -cvzf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: model/transformers/pytorch/model.tar.gz to s3://sagemaker-us-east-1-211125778552/model/tensorflow-training-2024-03-03-04-02-13-539/transformer-pytorch/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./model/transformers/pytorch/model.tar.gz $transformer_pytorch_model_dir_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-06 15:39:05  246786601 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $transformer_pytorch_model_dir_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'transformer_pytorch_model_dir_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store transformer_pytorch_model_dir_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "autopilot_endpoint_arn                                -> 'arn:aws:sagemaker:us-east-1:211125778552:endpoint\n",
      "autopilot_model_arn                                   -> 'arn:aws:sagemaker:us-east-1:211125778552:model/au\n",
      "autopilot_train_s3_uri                                -> 's3://sagemaker-us-east-1-211125778552/data/amazon\n",
      "balance_dataset                                       -> True\n",
      "balanced_bias_data_jsonlines_s3_uri                   -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "balanced_bias_data_s3_uri                             -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "bias_data_s3_uri                                      -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "comprehend_endpoint_arn                               -> 'arn:aws:comprehend:us-east-1:211125778552:documen\n",
      "comprehend_train_s3_uri                               -> 's3://sagemaker-us-east-1-211125778552/data/amazon\n",
      "comprehend_training_job_arn                           -> 'arn:aws:comprehend:us-east-1:211125778552:documen\n",
      "experiment_name                                       -> 'Amazon-Customer-Reviews-BERT-Experiment-170943649\n",
      "feature_group_name                                    -> 'reviews-feature-group-1709436496'\n",
      "feature_store_offline_prefix                          -> 'reviews-feature-store-1709436496'\n",
      "ingest_create_athena_db_passed                        -> True\n",
      "ingest_create_athena_table_parquet_passed             -> True\n",
      "ingest_create_athena_table_tsv_passed                 -> True\n",
      "max_seq_length                                        -> 64\n",
      "processed_test_data_s3_uri                            -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processed_train_data_s3_uri                           -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processed_validation_data_s3_uri                      -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "raw_input_data_s3_uri                                 -> 's3://sagemaker-us-east-1-211125778552/amazon-revi\n",
      "s3_private_path_tsv                                   -> 's3://sagemaker-us-east-1-211125778552/amazon-revi\n",
      "s3_public_path_tsv                                    -> 's3://dsoaws/amazon-reviews-pds/tsv'\n",
      "setup_dependencies_passed                             -> True\n",
      "setup_iam_roles_passed                                -> True\n",
      "setup_s3_bucket_passed                                -> True\n",
      "test_split_percentage                                 -> 0.2\n",
      "train_split_percentage                                -> 0.6\n",
      "training_job_name                                     -> 'tensorflow-training-2024-03-03-04-02-13-539'\n",
      "transformer_pytorch_model_dir_s3_uri                  -> 's3://sagemaker-us-east-1-211125778552/model/tenso\n",
      "trial_name                                            -> 'trial-1709436495'\n",
      "validation_split_percentage                           -> 0.2\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\n    Jupyter.notebook.save_checkpoint();\n    Jupyter.notebook.session.delete();\n}\ncatch(err) {\n    // NoOp\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "data_science_on_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
