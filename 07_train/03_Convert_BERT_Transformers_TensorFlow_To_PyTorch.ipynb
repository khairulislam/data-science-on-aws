{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the TensorFlow-Trained BERT Model to a PyTorch Model\n",
    "We do this to show HuggingFace's ability to convert models between TensorFlow and PyTorch.\n",
    "\n",
    "We will subsequently deploy the model as a PyTorch model using the TorchServe Inference Container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker.config INFO - Not applying SDK defaults from location: /etc/xdg/sagemaker/config.yaml\n",
      "sagemaker.config INFO - Not applying SDK defaults from location: /home/sagemaker-user/.config/sagemaker/config.yaml\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r training_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    training_job_name\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please wait for the Training notebook to finish.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous training_job_name: tensorflow-training-2024-10-23-01-14-51-869\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous training_job_name: {}\".format(training_job_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the TensorFlow-Trained Model from S3 to this Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = \"./model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-211125778552/tensorflow-training-2024-10-23-01-14-51-869/output/model.tar.gz to model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz $models_dir/model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import pickle as pkl\n",
    "\n",
    "try:\n",
    "    tar = tarfile.open(\"{}/model.tar.gz\".format(models_dir))\n",
    "    tar.extractall(path=models_dir)\n",
    "    tar.close()\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] in tar operation: {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 837644\n",
      "drwxr-xr-x  8 sagemaker-user users       127 Oct 23 01:32 .\n",
      "drwxr-xr-x 21 sagemaker-user users      4096 Oct 23 01:26 ..\n",
      "drwxr-xr-x  2 sagemaker-user users        26 Oct 23 01:24 code\n",
      "drwxr-xr-x  2 sagemaker-user users        57 Oct 23 01:25 metrics\n",
      "-rw-r--r--  1 sagemaker-user users 857740258 Oct 23 01:26 model.tar.gz\n",
      "drwxr-xr-x  4 sagemaker-user users        37 Oct 23 01:20 tensorboard\n",
      "drwxr-xr-x  3 sagemaker-user users        25 Oct 23 01:17 tensorflow\n",
      "drwxr-xr-x  2 sagemaker-user users        61 Oct 23 01:24 test_data\n",
      "drwxr-xr-x  3 sagemaker-user users        24 Oct 23 01:17 transformers\n"
     ]
    }
   ],
   "source": [
    "!ls -al $models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261688\n",
      "drwxr-xr-x 2 sagemaker-user users        44 Oct 23 01:22 .\n",
      "drwxr-xr-x 3 sagemaker-user users        24 Oct 23 01:17 ..\n",
      "-rw-r--r-- 1 sagemaker-user users       689 Oct 23 01:22 config.json\n",
      "-rw-r--r-- 1 sagemaker-user users 267961728 Oct 23 01:22 tf_model.h5\n"
     ]
    }
   ],
   "source": [
    "transformer_model_dir = \"{}/transformers/fine-tuned/\".format(models_dir)\n",
    "\n",
    "!ls -al $transformer_model_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"id2label\": {\n",
      "    \"0\": 1,\n",
      "    \"1\": 2,\n",
      "    \"2\": 3,\n",
      "    \"3\": 4,\n",
      "    \"4\": 5\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"label2id\": {\n",
      "    \"1\": 0,\n",
      "    \"2\": 1,\n",
      "    \"3\": 2,\n",
      "    \"4\": 3,\n",
      "    \"5\": 4\n",
      "  },\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.10.0.dev0\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "cat $transformer_model_dir/config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the TensorFlow Model to PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-23 01:32:35.346641: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-23 01:32:35.622660: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-10-23 01:32:35.841256: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-23 01:32:35.998026: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-23 01:32:36.051424: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-23 01:32:36.430755: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-23 01:32:39.252734: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2024-10-23 01:32:43.335924: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-10-23 01:32:43.871021: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-10-23 01:32:43.965292: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-10-23 01:33:01.175359: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "2024-10-23 01:33:01.438573: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n",
      "All TF 2.0 model weights were used when initializing DistilBertForSequenceClassification.\n",
      "\n",
      "All the weights of DistilBertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use DistilBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertForSequenceClassification  # PyTorch version\n",
    "\n",
    "try:\n",
    "    loaded_pytorch_model = DistilBertForSequenceClassification.from_pretrained(\n",
    "        transformer_model_dir,\n",
    "        id2label={0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n",
    "        label2id={1: 0, 2: 1, 3: 2, 4: 3, 5: 4},\n",
    "        from_tf=True,\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(\"[ERROR] in loading model {}: \".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'transformers.models.distilbert.modeling_distilbert.DistilBertForSequenceClassification'>\n",
      "DistilBertForSequenceClassification(\n",
      "  (distilbert): DistilBertModel(\n",
      "    (embeddings): Embeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (transformer): Transformer(\n",
      "      (layer): ModuleList(\n",
      "        (0-5): 6 x TransformerBlock(\n",
      "          (attention): MultiHeadSelfAttention(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
      "          )\n",
      "          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "          (ffn): FFN(\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (activation): GELUActivation()\n",
      "          )\n",
      "          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
      "  (classifier): Linear(in_features=768, out_features=5, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(type(loaded_pytorch_model))\n",
    "print(loaded_pytorch_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Transformer/PyTorch Model with `.save_pretrained()`\n",
    "This will create `pytorch_model.bin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_models_dir = \"./model/transformers/pytorch\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_pytorch_model.save_pretrained(pytorch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261572\n",
      "drwxr-xr-x 2 sagemaker-user users        50 Oct 23 01:33 .\n",
      "drwxr-xr-x 4 sagemaker-user users        39 Oct 23 01:33 ..\n",
      "-rw-r--r-- 1 sagemaker-user users       735 Oct 23 01:33 config.json\n",
      "-rw-r--r-- 1 sagemaker-user users 267841796 Oct 23 01:33 model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!ls -al $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_model = DistilBertForSequenceClassification.from_pretrained(pytorch_models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 261572\n",
      "drwxr-xr-x 2 sagemaker-user users        50 Oct 23 01:33 .\n",
      "drwxr-xr-x 4 sagemaker-user users        39 Oct 23 01:33 ..\n",
      "-rw-r--r-- 1 sagemaker-user users       735 Oct 23 01:33 config.json\n",
      "-rw-r--r-- 1 sagemaker-user users 267841796 Oct 23 01:33 model.safetensors\n"
     ]
    }
   ],
   "source": [
    "!ls -al $pytorch_models_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Incorrect path_or_model_id: './model/transformers/pytorch/pytorch_model.bin'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m    399\u001b[0m         path_or_repo_id,\n\u001b[1;32m    400\u001b[0m         filename,\n\u001b[1;32m    401\u001b[0m         subfolder\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m \u001b[39mif\u001b[39;49;00m \u001b[39mlen\u001b[39;49m(subfolder) \u001b[39m==\u001b[39;49m \u001b[39m0\u001b[39;49m \u001b[39melse\u001b[39;49;00m subfolder,\n\u001b[1;32m    402\u001b[0m         repo_type\u001b[39m=\u001b[39;49mrepo_type,\n\u001b[1;32m    403\u001b[0m         revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m    404\u001b[0m         cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m    405\u001b[0m         user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m    406\u001b[0m         force_download\u001b[39m=\u001b[39;49mforce_download,\n\u001b[1;32m    407\u001b[0m         proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m    408\u001b[0m         resume_download\u001b[39m=\u001b[39;49mresume_download,\n\u001b[1;32m    409\u001b[0m         token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m    410\u001b[0m         local_files_only\u001b[39m=\u001b[39;49mlocal_files_only,\n\u001b[1;32m    411\u001b[0m     )\n\u001b[1;32m    412\u001b[0m \u001b[39mexcept\u001b[39;00m GatedRepoError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_deprecation.py:101\u001b[0m, in \u001b[0;36m_deprecate_arguments.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(message, \u001b[39mFutureWarning\u001b[39;00m)\n\u001b[0;32m--> 101\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:106\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 106\u001b[0m     validate_repo_id(arg_value)\n\u001b[1;32m    108\u001b[0m \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:154\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mif\u001b[39;00m repo_id\u001b[39m.\u001b[39mcount(\u001b[39m\"\u001b[39m\u001b[39m/\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    155\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    157\u001b[0m     )\n\u001b[1;32m    159\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': './model/transformers/pytorch/pytorch_model.bin'. Use `repo_type` argument if needed.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/sagemaker-user/data-science-on-aws/07_train/03_Convert_BERT_Transformers_TensorFlow_To_PyTorch.ipynb Cell 25\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://99rg3smwj9rkyho.studio.us-east-1.sagemaker.aws/home/sagemaker-user/data-science-on-aws/07_train/03_Convert_BERT_Transformers_TensorFlow_To_PyTorch.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m config \u001b[39m=\u001b[39m DistilBertConfig\u001b[39m.\u001b[39mfrom_json_file(\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/config.json\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(pytorch_models_dir))\n\u001b[1;32m      <a href='vscode-notebook-cell://99rg3smwj9rkyho.studio.us-east-1.sagemaker.aws/home/sagemaker-user/data-science-on-aws/07_train/03_Convert_BERT_Transformers_TensorFlow_To_PyTorch.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(pytorch_models_dir, \u001b[39m\"\u001b[39m\u001b[39mpytorch_model.bin\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://99rg3smwj9rkyho.studio.us-east-1.sagemaker.aws/home/sagemaker-user/data-science-on-aws/07_train/03_Convert_BERT_Transformers_TensorFlow_To_PyTorch.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m model \u001b[39m=\u001b[39m DistilBertForSequenceClassification\u001b[39m.\u001b[39;49mfrom_pretrained(model_path, config\u001b[39m=\u001b[39;49mconfig)\n\u001b[1;32m     <a href='vscode-notebook-cell://99rg3smwj9rkyho.studio.us-east-1.sagemaker.aws/home/sagemaker-user/data-science-on-aws/07_train/03_Convert_BERT_Transformers_TensorFlow_To_PyTorch.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell://99rg3smwj9rkyho.studio.us-east-1.sagemaker.aws/home/sagemaker-user/data-science-on-aws/07_train/03_Convert_BERT_Transformers_TensorFlow_To_PyTorch.ipynb#X33sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m model\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:3306\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   3291\u001b[0m     \u001b[39m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[1;32m   3292\u001b[0m     cached_file_kwargs \u001b[39m=\u001b[39m {\n\u001b[1;32m   3293\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mcache_dir\u001b[39m\u001b[39m\"\u001b[39m: cache_dir,\n\u001b[1;32m   3294\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mforce_download\u001b[39m\u001b[39m\"\u001b[39m: force_download,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3304\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m_commit_hash\u001b[39m\u001b[39m\"\u001b[39m: commit_hash,\n\u001b[1;32m   3305\u001b[0m     }\n\u001b[0;32m-> 3306\u001b[0m     resolved_archive_file \u001b[39m=\u001b[39m cached_file(pretrained_model_name_or_path, filename, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcached_file_kwargs)\n\u001b[1;32m   3308\u001b[0m     \u001b[39m# Since we set _raise_exceptions_for_missing_entries=False, we don't get an exception but a None\u001b[39;00m\n\u001b[1;32m   3309\u001b[0m     \u001b[39m# result when internet is up, the repo and revision exist, but the file does not.\u001b[39;00m\n\u001b[1;32m   3310\u001b[0m     \u001b[39mif\u001b[39;00m resolved_archive_file \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m filename \u001b[39m==\u001b[39m _add_variant(SAFE_WEIGHTS_NAME, variant):\n\u001b[1;32m   3311\u001b[0m         \u001b[39m# Maybe the checkpoint is sharded, we try to grab the index name in this case.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:462\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThere was a specific connection error when trying to load \u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merr\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    461\u001b[0m \u001b[39mexcept\u001b[39;00m HFValidationError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m--> 462\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    463\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mIncorrect path_or_model_id: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mpath_or_repo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    464\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[39mreturn\u001b[39;00m resolved_file\n",
      "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: './model/transformers/pytorch/pytorch_model.bin'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification\n",
    "from transformers import DistilBertConfig\n",
    "\n",
    "config = DistilBertConfig.from_json_file(\"{}/config.json\".format(pytorch_models_dir))\n",
    "\n",
    "model_path = \"{}/{}\".format(pytorch_models_dir, \"pytorch_model.bin\")\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path, config=config)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-03-06 15:38:46.454 default:453 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "[2024-03-06 15:38:46.630 default:453 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "input_data: [{\"features\": [\"This is great!\"]},                {\"features\": [\"This is bad.\"]}]\n",
      "data_json: [{'features': ['This is great!']}, {'features': ['This is bad.']}]\n",
      "data_json_line: {'features': ['This is great!']}\n",
      "type(data_json_line): <class 'dict'>\n",
      "review_body: This is great!\n",
      "output: (tensor([[ 0.0913, -0.0083, -0.1442, -0.0366,  0.0816]],\n",
      "       grad_fn=<AddmmBackward>),)\n",
      "softmax_output: tensor([[0.2190, 0.1983, 0.1731, 0.1927, 0.2169]], grad_fn=<SoftmaxBackward>)\n",
      "predicted_class: 1\n",
      "data_json_line: {'features': ['This is bad.']}\n",
      "type(data_json_line): <class 'dict'>\n",
      "review_body: This is bad.\n",
      "output: (tensor([[ 0.0363,  0.0183, -0.0332, -0.0609,  0.0948]],\n",
      "       grad_fn=<AddmmBackward>),)\n",
      "softmax_output: tensor([[0.2048, 0.2012, 0.1911, 0.1858, 0.2171]], grad_fn=<SoftmaxBackward>)\n",
      "predicted_class: 5\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import smdebug.pytorch as smd\n",
    "from torch import nn\n",
    "\n",
    "max_seq_length = 64\n",
    "classes = [1, 2, 3, 4, 5]\n",
    "\n",
    "model.eval()\n",
    "\n",
    "input_data = '[{\"features\": [\"This is great!\"]}, \\\n",
    "               {\"features\": [\"This is bad.\"]}]'\n",
    "print(\"input_data: {}\".format(input_data))\n",
    "\n",
    "data_json = json.loads(input_data)\n",
    "print(\"data_json: {}\".format(data_json))\n",
    "\n",
    "predicted_classes = []\n",
    "save_config = smd.SaveConfig(save_interval=1)\n",
    "# hook = smd.Hook(\"/tmp/tensors\", save_config=save_config, include_regex='.*')\n",
    "\n",
    "# hook.register_module(model)\n",
    "\n",
    "for data_json_line in data_json:\n",
    "    print(\"data_json_line: {}\".format(data_json_line))\n",
    "    print(\"type(data_json_line): {}\".format(type(data_json_line)))\n",
    "\n",
    "    review_body = data_json_line[\"features\"][0]\n",
    "    print(\"\"\"review_body: {}\"\"\".format(review_body))\n",
    "\n",
    "    encode_plus_token = tokenizer.encode_plus(\n",
    "        review_body,\n",
    "        max_length=max_seq_length,\n",
    "        add_special_tokens=False,\n",
    "        #        return_token_type_ids=False,\n",
    "        return_token_type_ids=None,\n",
    "        #        pad_to_max_length=True,\n",
    "        padding=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "    )\n",
    "\n",
    "    input_ids = encode_plus_token[\"input_ids\"]\n",
    "\n",
    "    #    hook._write_raw_tensor_simple(\"input_tokens\", tokenizer.tokenize(review_body))\n",
    "    attention_mask = encode_plus_token[\"attention_mask\"]\n",
    "\n",
    "    output = model(input_ids, attention_mask)\n",
    "    print(\"output: {}\".format(output))\n",
    "\n",
    "    softmax_fn = nn.Softmax(dim=1)\n",
    "    softmax_output = softmax_fn(output[0])\n",
    "    print(\"softmax_output: {}\".format(softmax_output))\n",
    "\n",
    "    _, prediction = torch.max(softmax_output, dim=1)\n",
    "\n",
    "    predicted_class_idx = prediction.item()\n",
    "    predicted_class = classes[predicted_class_idx]\n",
    "    print(\"predicted_class: {}\".format(predicted_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Transformer/PyTorch Model to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/model/tensorflow-training-2024-03-03-04-02-13-539/transformer-pytorch/\n"
     ]
    }
   ],
   "source": [
    "transformer_pytorch_model_dir_s3_uri = \"s3://{}/model/{}/transformer-pytorch/\".format(bucket, training_job_name)\n",
    "print(transformer_pytorch_model_dir_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv ./model/transformers/pytorch/pytorch_model.bin ./model/transformers/pytorch/model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json\n",
      "model.pth\n"
     ]
    }
   ],
   "source": [
    "!cd ./model/transformers/pytorch/ && tar -cvzf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: model/transformers/pytorch/model.tar.gz to s3://sagemaker-us-east-1-211125778552/model/tensorflow-training-2024-03-03-04-02-13-539/transformer-pytorch/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp ./model/transformers/pytorch/model.tar.gz $transformer_pytorch_model_dir_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-03-06 15:39:05  246786601 model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $transformer_pytorch_model_dir_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'transformer_pytorch_model_dir_s3_uri' (str)\n"
     ]
    }
   ],
   "source": [
    "%store transformer_pytorch_model_dir_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "autopilot_endpoint_arn                                -> 'arn:aws:sagemaker:us-east-1:211125778552:endpoint\n",
      "autopilot_model_arn                                   -> 'arn:aws:sagemaker:us-east-1:211125778552:model/au\n",
      "autopilot_train_s3_uri                                -> 's3://sagemaker-us-east-1-211125778552/data/amazon\n",
      "balance_dataset                                       -> True\n",
      "balanced_bias_data_jsonlines_s3_uri                   -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "balanced_bias_data_s3_uri                             -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "bias_data_s3_uri                                      -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "comprehend_endpoint_arn                               -> 'arn:aws:comprehend:us-east-1:211125778552:documen\n",
      "comprehend_train_s3_uri                               -> 's3://sagemaker-us-east-1-211125778552/data/amazon\n",
      "comprehend_training_job_arn                           -> 'arn:aws:comprehend:us-east-1:211125778552:documen\n",
      "experiment_name                                       -> 'Amazon-Customer-Reviews-BERT-Experiment-170943649\n",
      "feature_group_name                                    -> 'reviews-feature-group-1709436496'\n",
      "feature_store_offline_prefix                          -> 'reviews-feature-store-1709436496'\n",
      "ingest_create_athena_db_passed                        -> True\n",
      "ingest_create_athena_table_parquet_passed             -> True\n",
      "ingest_create_athena_table_tsv_passed                 -> True\n",
      "max_seq_length                                        -> 64\n",
      "processed_test_data_s3_uri                            -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processed_train_data_s3_uri                           -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processed_validation_data_s3_uri                      -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "raw_input_data_s3_uri                                 -> 's3://sagemaker-us-east-1-211125778552/amazon-revi\n",
      "s3_private_path_tsv                                   -> 's3://sagemaker-us-east-1-211125778552/amazon-revi\n",
      "s3_public_path_tsv                                    -> 's3://dsoaws/amazon-reviews-pds/tsv'\n",
      "setup_dependencies_passed                             -> True\n",
      "setup_iam_roles_passed                                -> True\n",
      "setup_s3_bucket_passed                                -> True\n",
      "test_split_percentage                                 -> 0.2\n",
      "train_split_percentage                                -> 0.6\n",
      "training_job_name                                     -> 'tensorflow-training-2024-03-03-04-02-13-539'\n",
      "transformer_pytorch_model_dir_s3_uri                  -> 's3://sagemaker-us-east-1-211125778552/model/tenso\n",
      "trial_name                                            -> 'trial-1709436495'\n",
      "validation_split_percentage                           -> 0.2\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\n    Jupyter.notebook.save_checkpoint();\n    Jupyter.notebook.session.delete();\n}\ncatch(err) {\n    // NoOp\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "data_science_on_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
