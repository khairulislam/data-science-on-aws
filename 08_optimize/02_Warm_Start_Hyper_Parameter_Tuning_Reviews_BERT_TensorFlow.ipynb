{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warm Start from a Completed Hyper-Parameter Tuning Job\n",
    "Once the previous hyper-parameter tuning job completes, we can perform another round of optimization using `Warm Start`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warm start configuration allows you to create a new tuning job with the learning gathered in a parent tuning job by specifying up to 5 parent tuning jobs. If a warm start configuration is specified, Automatic Model Tuning will load the previous [hyperparameter set, objective metrics values] to warm start the new tuning job. This means, you can continue optimizing your model from the point you finished your previous tuning job experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/hpt-warmstart.png\" width=\"90%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Requisite\n",
    "\n",
    "## The previous hyper-parameter tuning job needs to complete, before we can perform another round of optimization using `Warm Start`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r tuning_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tuning_job_name\n",
    "    print(\"[OK]\")\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous Hyperparameter Tuning notebook.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-240306-1631\n"
     ]
    }
   ],
   "source": [
    "print(tuning_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the status of the previous Hyperparameter Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_description = sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] Previous Tuning Job has completed. Please continue.\n"
     ]
    }
   ],
   "source": [
    "if not bool(job_description):\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous Hyperparameter Tuning notebook before you continue.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "elif job_description[\"HyperParameterTuningJobStatus\"] == \"Completed\":\n",
    "    print(\"[OK] Previous Tuning Job has completed. Please continue.\")\n",
    "else:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the previous Hyperparameter Tuning notebook.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify the S3 Location of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r processed_train_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    processed_train_data_s3_uri\n",
    "    print(\"[OK]\")\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the previous PREPARE section before you continue.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-train\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r processed_validation_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    processed_validation_data_s3_uri\n",
    "    print(\"[OK]\")\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the previous PREPARE section before you continue.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-validation\n"
     ]
    }
   ],
   "source": [
    "print(processed_validation_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r processed_test_data_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    processed_test_data_s3_uri\n",
    "    print(\"[OK]\")\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the previous PREPARE section before you continue.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-test\n"
     ]
    }
   ],
   "source": [
    "print(processed_test_data_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-train\n",
      "2024-03-03 03:59:47    6988023 part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord\n",
      "2024-03-03 03:59:47    1541730 part-algo-1-amazon_reviews_us_Gift_Card_v1_00.tfrecord\n",
      "2024-03-03 03:59:42    7809721 part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord\n"
     ]
    }
   ],
   "source": [
    "print(processed_train_data_s3_uri)\n",
    "!aws s3 ls $processed_train_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-validation\n",
      "2024-03-03 03:59:47    2330909 part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord\n",
      "2024-03-03 03:59:47     513937 part-algo-1-amazon_reviews_us_Gift_Card_v1_00.tfrecord\n",
      "2024-03-03 03:59:42    2604075 part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord\n"
     ]
    }
   ],
   "source": [
    "print(processed_validation_data_s3_uri)\n",
    "!aws s3 ls $processed_validation_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-test\n",
      "2024-03-03 03:59:47    2326926 part-algo-1-amazon_reviews_us_Digital_Software_v1_00.tfrecord\n",
      "2024-03-03 03:59:47     514186 part-algo-1-amazon_reviews_us_Gift_Card_v1_00.tfrecord\n",
      "2024-03-03 03:59:42    2597730 part-algo-2-amazon_reviews_us_Digital_Video_Games_v1_00.tfrecord\n"
     ]
    }
   ],
   "source": [
    "print(processed_test_data_s3_uri)\n",
    "!aws s3 ls $processed_test_data_s3_uri/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-train', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-validation', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n",
      "{'DataSource': {'S3DataSource': {'S3DataType': 'S3Prefix', 'S3Uri': 's3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-test', 'S3DataDistributionType': 'ShardedByS3Key'}}}\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "s3_input_train_data = TrainingInput(s3_data=processed_train_data_s3_uri, distribution=\"ShardedByS3Key\")\n",
    "s3_input_validation_data = TrainingInput(s3_data=processed_validation_data_s3_uri, distribution=\"ShardedByS3Key\")\n",
    "s3_input_test_data = TrainingInput(s3_data=processed_test_data_s3_uri, distribution=\"ShardedByS3Key\")\n",
    "\n",
    "print(s3_input_train_data.config)\n",
    "print(s3_input_validation_data.config)\n",
    "print(s3_input_test_data.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import time\n",
      "import random\n",
      "import pandas as pd\n",
      "from glob import glob\n",
      "import pprint\n",
      "import argparse\n",
      "import json\n",
      "import subprocess\n",
      "import sys\n",
      "import os\n",
      "import csv\n",
      "\n",
      "# subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'tensorflow==2.1.0'])\n",
      "import tensorflow as tf\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"transformers==3.5.1\"])\n",
      "# subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'sagemaker-tensorflow==2.1.0.1.0.0'])\n",
      "# subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'smdebug==0.9.3'])\n",
      "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"scikit-learn==0.23.1\"])\n",
      "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"matplotlib==3.2.1\"])\n",
      "\n",
      "from transformers import DistilBertTokenizer\n",
      "from transformers import DistilBertConfig\n",
      "from transformers import TFDistilBertForSequenceClassification\n",
      "\n",
      "from tensorflow.keras.callbacks import ModelCheckpoint\n",
      "from tensorflow.keras.models import load_model\n",
      "\n",
      "\n",
      "CLASSES = [1, 2, 3, 4, 5]\n",
      "\n",
      "\n",
      "def select_data_and_label_from_record(record):\n",
      "    x = {\"input_ids\": record[\"input_ids\"], \"input_mask\": record[\"input_mask\"], \"segment_ids\": record[\"segment_ids\"]}\n",
      "\n",
      "    y = record[\"label_ids\"]\n",
      "\n",
      "    return (x, y)\n",
      "\n",
      "\n",
      "def file_based_input_dataset_builder(\n",
      "    channel,\n",
      "    input_filenames,\n",
      "    pipe_mode,\n",
      "    is_training,\n",
      "    drop_remainder,\n",
      "    batch_size,\n",
      "    epochs,\n",
      "    steps_per_epoch,\n",
      "    max_seq_length,\n",
      "):\n",
      "\n",
      "    # For training, we want a lot of parallel reading and shuffling.\n",
      "    # For eval, we want no shuffling and parallel reading doesn't matter.\n",
      "\n",
      "    if pipe_mode:\n",
      "        print(\"***** Using pipe_mode with channel {}\".format(channel))\n",
      "        from sagemaker_tensorflow import PipeModeDataset\n",
      "\n",
      "        dataset = PipeModeDataset(channel=channel, record_format=\"TFRecord\")\n",
      "    else:\n",
      "        print(\"***** Using input_filenames {}\".format(input_filenames))\n",
      "        dataset = tf.data.TFRecordDataset(input_filenames)\n",
      "\n",
      "    dataset = dataset.repeat(epochs * steps_per_epoch * 100)\n",
      "    #    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
      "\n",
      "    name_to_features = {\n",
      "        \"input_ids\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
      "        \"input_mask\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
      "        \"segment_ids\": tf.io.FixedLenFeature([max_seq_length], tf.int64),\n",
      "        \"label_ids\": tf.io.FixedLenFeature([], tf.int64),\n",
      "    }\n",
      "\n",
      "    def _decode_record(record, name_to_features):\n",
      "        \"\"\"Decodes a record to a TensorFlow example.\"\"\"\n",
      "        record = tf.io.parse_single_example(record, name_to_features)\n",
      "        return record\n",
      "\n",
      "    dataset = dataset.apply(\n",
      "        tf.data.experimental.map_and_batch(\n",
      "            lambda record: _decode_record(record, name_to_features),\n",
      "            batch_size=batch_size,\n",
      "            drop_remainder=drop_remainder,\n",
      "            num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
      "        )\n",
      "    )\n",
      "\n",
      "    #    dataset.cache()\n",
      "\n",
      "    dataset = dataset.shuffle(buffer_size=1000, reshuffle_each_iteration=True)\n",
      "\n",
      "    row_count = 0\n",
      "    print(\"**************** {} *****************\".format(channel))\n",
      "    for row in dataset.as_numpy_iterator():\n",
      "        print(row)\n",
      "        if row_count == 5:\n",
      "            break\n",
      "        row_count = row_count + 1\n",
      "\n",
      "    return dataset\n",
      "\n",
      "\n",
      "def load_checkpoint_model(checkpoint_path):\n",
      "    import glob\n",
      "    import os\n",
      "\n",
      "    glob_pattern = os.path.join(checkpoint_path, \"*.h5\")\n",
      "    print(\"glob pattern {}\".format(glob_pattern))\n",
      "\n",
      "    list_of_checkpoint_files = glob.glob(glob_pattern)\n",
      "    print(\"List of checkpoint files {}\".format(list_of_checkpoint_files))\n",
      "\n",
      "    latest_checkpoint_file = max(list_of_checkpoint_files)\n",
      "    print(\"Latest checkpoint file {}\".format(latest_checkpoint_file))\n",
      "\n",
      "    initial_epoch_number_str = latest_checkpoint_file.rsplit(\"_\", 1)[-1].split(\".h5\")[0]\n",
      "    initial_epoch_number = int(initial_epoch_number_str)\n",
      "\n",
      "    loaded_model = TFDistilBertForSequenceClassification.from_pretrained(latest_checkpoint_file, config=config)\n",
      "\n",
      "    print(\"loaded_model {}\".format(loaded_model))\n",
      "    print(\"initial_epoch_number {}\".format(initial_epoch_number))\n",
      "\n",
      "    return loaded_model, initial_epoch_number\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    parser.add_argument(\"--train_data\", type=str, default=os.environ[\"SM_CHANNEL_TRAIN\"])\n",
      "    parser.add_argument(\"--validation_data\", type=str, default=os.environ[\"SM_CHANNEL_VALIDATION\"])\n",
      "    parser.add_argument(\"--test_data\", type=str, default=os.environ[\"SM_CHANNEL_TEST\"])\n",
      "    parser.add_argument(\"--output_dir\", type=str, default=os.environ[\"SM_OUTPUT_DIR\"])\n",
      "    parser.add_argument(\"--hosts\", type=list, default=json.loads(os.environ[\"SM_HOSTS\"]))\n",
      "    parser.add_argument(\"--current_host\", type=str, default=os.environ[\"SM_CURRENT_HOST\"])\n",
      "    parser.add_argument(\"--num_gpus\", type=int, default=os.environ[\"SM_NUM_GPUS\"])\n",
      "    parser.add_argument(\"--checkpoint_base_path\", type=str, default=\"/opt/ml/checkpoints\")\n",
      "    parser.add_argument(\"--use_xla\", type=eval, default=False)\n",
      "    parser.add_argument(\"--use_amp\", type=eval, default=False)\n",
      "    parser.add_argument(\"--max_seq_length\", type=int, default=64)\n",
      "    parser.add_argument(\"--train_batch_size\", type=int, default=128)\n",
      "    parser.add_argument(\"--validation_batch_size\", type=int, default=256)\n",
      "    parser.add_argument(\"--test_batch_size\", type=int, default=256)\n",
      "    parser.add_argument(\"--epochs\", type=int, default=2)\n",
      "    parser.add_argument(\"--learning_rate\", type=float, default=0.00003)\n",
      "    parser.add_argument(\"--epsilon\", type=float, default=0.00000001)\n",
      "    parser.add_argument(\"--train_steps_per_epoch\", type=int, default=None)\n",
      "    parser.add_argument(\"--validation_steps\", type=int, default=None)\n",
      "    parser.add_argument(\"--test_steps\", type=int, default=None)\n",
      "    parser.add_argument(\"--freeze_bert_layer\", type=eval, default=False)\n",
      "    parser.add_argument(\"--enable_sagemaker_debugger\", type=eval, default=False)\n",
      "    parser.add_argument(\"--run_validation\", type=eval, default=False)\n",
      "    parser.add_argument(\"--run_test\", type=eval, default=False)\n",
      "    parser.add_argument(\"--run_sample_predictions\", type=eval, default=False)\n",
      "    parser.add_argument(\"--enable_tensorboard\", type=eval, default=False)\n",
      "    parser.add_argument(\"--enable_checkpointing\", type=eval, default=False)\n",
      "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ[\"SM_OUTPUT_DATA_DIR\"])  # This is unused\n",
      "\n",
      "    # This points to the S3 location - this should not be used by our code\n",
      "    # We should use /opt/ml/model/ instead\n",
      "    # parser.add_argument('--model_dir',\n",
      "    #                     type=str,\n",
      "    #                     default=os.environ['SM_MODEL_DIR'])\n",
      "\n",
      "    args, _ = parser.parse_known_args()\n",
      "    print(\"Args:\")\n",
      "    print(args)\n",
      "\n",
      "    env_var = os.environ\n",
      "    print(\"Environment Variables:\")\n",
      "    pprint.pprint(dict(env_var), width=1)\n",
      "\n",
      "    print(\"SM_TRAINING_ENV {}\".format(env_var[\"SM_TRAINING_ENV\"]))\n",
      "    sm_training_env_json = json.loads(env_var[\"SM_TRAINING_ENV\"])\n",
      "    is_master = sm_training_env_json[\"is_master\"]\n",
      "    print(\"is_master {}\".format(is_master))\n",
      "\n",
      "    train_data = args.train_data\n",
      "    print(\"train_data {}\".format(train_data))\n",
      "    validation_data = args.validation_data\n",
      "    print(\"validation_data {}\".format(validation_data))\n",
      "    test_data = args.test_data\n",
      "    print(\"test_data {}\".format(test_data))\n",
      "    local_model_dir = os.environ[\"SM_MODEL_DIR\"]\n",
      "    output_dir = args.output_dir\n",
      "    print(\"output_dir {}\".format(output_dir))\n",
      "    hosts = args.hosts\n",
      "    print(\"hosts {}\".format(hosts))\n",
      "    current_host = args.current_host\n",
      "    print(\"current_host {}\".format(current_host))\n",
      "    num_gpus = args.num_gpus\n",
      "    print(\"num_gpus {}\".format(num_gpus))\n",
      "    job_name = os.environ[\"SAGEMAKER_JOB_NAME\"]\n",
      "    print(\"job_name {}\".format(job_name))\n",
      "    use_xla = args.use_xla\n",
      "    print(\"use_xla {}\".format(use_xla))\n",
      "    use_amp = args.use_amp\n",
      "    print(\"use_amp {}\".format(use_amp))\n",
      "    max_seq_length = args.max_seq_length\n",
      "    print(\"max_seq_length {}\".format(max_seq_length))\n",
      "    train_batch_size = args.train_batch_size\n",
      "    print(\"train_batch_size {}\".format(train_batch_size))\n",
      "    validation_batch_size = args.validation_batch_size\n",
      "    print(\"validation_batch_size {}\".format(validation_batch_size))\n",
      "    test_batch_size = args.test_batch_size\n",
      "    print(\"test_batch_size {}\".format(test_batch_size))\n",
      "    epochs = args.epochs\n",
      "    print(\"epochs {}\".format(epochs))\n",
      "    learning_rate = args.learning_rate\n",
      "    print(\"learning_rate {}\".format(learning_rate))\n",
      "    epsilon = args.epsilon\n",
      "    print(\"epsilon {}\".format(epsilon))\n",
      "    train_steps_per_epoch = args.train_steps_per_epoch\n",
      "    print(\"train_steps_per_epoch {}\".format(train_steps_per_epoch))\n",
      "    validation_steps = args.validation_steps\n",
      "    print(\"validation_steps {}\".format(validation_steps))\n",
      "    test_steps = args.test_steps\n",
      "    print(\"test_steps {}\".format(test_steps))\n",
      "    freeze_bert_layer = args.freeze_bert_layer\n",
      "    print(\"freeze_bert_layer {}\".format(freeze_bert_layer))\n",
      "    enable_sagemaker_debugger = args.enable_sagemaker_debugger\n",
      "    print(\"enable_sagemaker_debugger {}\".format(enable_sagemaker_debugger))\n",
      "    run_validation = args.run_validation\n",
      "    print(\"run_validation {}\".format(run_validation))\n",
      "    run_test = args.run_test\n",
      "    print(\"run_test {}\".format(run_test))\n",
      "    run_sample_predictions = args.run_sample_predictions\n",
      "    print(\"run_sample_predictions {}\".format(run_sample_predictions))\n",
      "    enable_tensorboard = args.enable_tensorboard\n",
      "    print(\"enable_tensorboard {}\".format(enable_tensorboard))\n",
      "    enable_checkpointing = args.enable_checkpointing\n",
      "    print(\"enable_checkpointing {}\".format(enable_checkpointing))\n",
      "\n",
      "    checkpoint_base_path = args.checkpoint_base_path\n",
      "    print(\"checkpoint_base_path {}\".format(checkpoint_base_path))\n",
      "\n",
      "    if is_master:\n",
      "        checkpoint_path = checkpoint_base_path\n",
      "    else:\n",
      "        checkpoint_path = \"/tmp/checkpoints\"\n",
      "    print(\"checkpoint_path {}\".format(checkpoint_path))\n",
      "\n",
      "    # Determine if PipeMode is enabled\n",
      "    pipe_mode_str = os.environ.get(\"SM_INPUT_DATA_CONFIG\", \"\")\n",
      "    pipe_mode = pipe_mode_str.find(\"Pipe\") >= 0\n",
      "    print(\"Using pipe_mode: {}\".format(pipe_mode))\n",
      "\n",
      "    # Model Output\n",
      "    transformer_fine_tuned_model_path = os.path.join(local_model_dir, \"transformers/fine-tuned/\")\n",
      "    os.makedirs(transformer_fine_tuned_model_path, exist_ok=True)\n",
      "\n",
      "    # SavedModel Output\n",
      "    tensorflow_saved_model_path = os.path.join(local_model_dir, \"tensorflow/saved_model/0\")\n",
      "    os.makedirs(tensorflow_saved_model_path, exist_ok=True)\n",
      "\n",
      "    # Tensorboard Logs\n",
      "    tensorboard_logs_path = os.path.join(local_model_dir, \"tensorboard/\")\n",
      "    os.makedirs(tensorboard_logs_path, exist_ok=True)\n",
      "\n",
      "    # Commented out due to incompatibility with transformers library (possibly)\n",
      "    # Set the global precision mixed_precision policy to \"mixed_float16\"\n",
      "    #    mixed_precision_policy = 'mixed_float16'\n",
      "    #    print('Mixed precision policy {}'.format(mixed_precision_policy))\n",
      "    #    policy = mixed_precision.Policy(mixed_precision_policy)\n",
      "    #    mixed_precision.set_policy(policy)\n",
      "\n",
      "    distributed_strategy = tf.distribute.MirroredStrategy()\n",
      "    # Comment out when using smdebug as smdebug does not support MultiWorkerMirroredStrategy() as of smdebug 0.8.0\n",
      "    # distributed_strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n",
      "    with distributed_strategy.scope():\n",
      "        tf.config.optimizer.set_jit(use_xla)\n",
      "        tf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": use_amp})\n",
      "\n",
      "        train_data_filenames = glob(os.path.join(train_data, \"*.tfrecord\"))\n",
      "        print(\"train_data_filenames {}\".format(train_data_filenames))\n",
      "        train_dataset = file_based_input_dataset_builder(\n",
      "            channel=\"train\",\n",
      "            input_filenames=train_data_filenames,\n",
      "            pipe_mode=pipe_mode,\n",
      "            is_training=True,\n",
      "            drop_remainder=False,\n",
      "            batch_size=train_batch_size,\n",
      "            epochs=epochs,\n",
      "            steps_per_epoch=train_steps_per_epoch,\n",
      "            max_seq_length=max_seq_length,\n",
      "        ).map(select_data_and_label_from_record)\n",
      "\n",
      "        tokenizer = None\n",
      "        config = None\n",
      "        model = None\n",
      "        transformer_model = None\n",
      "\n",
      "        # This is required when launching many instances at once...  the urllib request seems to get denied periodically\n",
      "        successful_download = False\n",
      "        retries = 0\n",
      "        while retries < 5 and not successful_download:\n",
      "            try:\n",
      "                tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
      "                config = DistilBertConfig.from_pretrained(\n",
      "                    \"distilbert-base-uncased\",\n",
      "                    num_labels=len(CLASSES),\n",
      "                    id2label={0: 1, 1: 2, 2: 3, 3: 4, 4: 5},\n",
      "                    label2id={1: 0, 2: 1, 3: 2, 4: 3, 5: 4},\n",
      "                )\n",
      "\n",
      "                transformer_model = TFDistilBertForSequenceClassification.from_pretrained(\n",
      "                    \"distilbert-base-uncased\", config=config\n",
      "                )\n",
      "\n",
      "                input_ids = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_ids\", dtype=\"int32\")\n",
      "                input_mask = tf.keras.layers.Input(shape=(max_seq_length,), name=\"input_mask\", dtype=\"int32\")\n",
      "\n",
      "                embedding_layer = transformer_model.distilbert(input_ids, attention_mask=input_mask)[0]\n",
      "                X = tf.keras.layers.Bidirectional(\n",
      "                    tf.keras.layers.LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.1)\n",
      "                )(embedding_layer)\n",
      "                X = tf.keras.layers.GlobalMaxPool1D()(X)\n",
      "                X = tf.keras.layers.Dense(50, activation=\"relu\")(X)\n",
      "                X = tf.keras.layers.Dropout(0.2)(X)\n",
      "                X = tf.keras.layers.Dense(len(CLASSES), activation=\"softmax\")(X)\n",
      "\n",
      "                model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=X)\n",
      "\n",
      "                for layer in model.layers[:3]:\n",
      "                    layer.trainable = not freeze_bert_layer\n",
      "\n",
      "                successful_download = True\n",
      "                print(\"Sucessfully downloaded after {} retries.\".format(retries))\n",
      "            except:\n",
      "                retries = retries + 1\n",
      "                random_sleep = random.randint(1, 30)\n",
      "                print(\"Retry #{}.  Sleeping for {} seconds\".format(retries, random_sleep))\n",
      "                time.sleep(random_sleep)\n",
      "\n",
      "        callbacks = []\n",
      "\n",
      "        initial_epoch_number = 0\n",
      "\n",
      "        if enable_checkpointing:\n",
      "            print(\"***** Checkpoint enabled *****\")\n",
      "\n",
      "            os.makedirs(checkpoint_path, exist_ok=True)\n",
      "            if os.listdir(checkpoint_path):\n",
      "                print(\"***** Found checkpoint *****\")\n",
      "                print(checkpoint_path)\n",
      "                model, initial_epoch_number = load_checkpoint_model(checkpoint_path)\n",
      "                print(\"***** Using checkpoint model {} *****\".format(model))\n",
      "\n",
      "            checkpoint_callback = ModelCheckpoint(\n",
      "                filepath=os.path.join(checkpoint_path, \"tf_model_{epoch:05d}.h5\"),\n",
      "                save_weights_only=False,\n",
      "                verbose=1,\n",
      "                monitor=\"val_accuracy\",\n",
      "            )\n",
      "            print(\"*** CHECKPOINT CALLBACK {} ***\".format(checkpoint_callback))\n",
      "            callbacks.append(checkpoint_callback)\n",
      "\n",
      "        if not tokenizer or not model or not config:\n",
      "            print(\"Not properly initialized...\")\n",
      "\n",
      "        optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate, epsilon=epsilon)\n",
      "        print(\"** use_amp {}\".format(use_amp))\n",
      "        if use_amp:\n",
      "            # loss scaling is currently required when using mixed precision\n",
      "            optimizer = tf.keras.mixed_precision.experimental.LossScaleOptimizer(optimizer, \"dynamic\")\n",
      "\n",
      "        print(\"enable_sagemaker_debugger {}\".format(enable_sagemaker_debugger))\n",
      "        if enable_sagemaker_debugger:\n",
      "            print(\"*** DEBUGGING ***\")\n",
      "            import smdebug.tensorflow as smd\n",
      "\n",
      "            # This assumes that we specified debugger_hook_config\n",
      "            debugger_callback = smd.KerasHook.create_from_json_file()\n",
      "            print(\"*** DEBUGGER CALLBACK {} ***\".format(debugger_callback))\n",
      "            callbacks.append(debugger_callback)\n",
      "            optimizer = debugger_callback.wrap_optimizer(optimizer)\n",
      "\n",
      "        if enable_tensorboard:\n",
      "            tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=tensorboard_logs_path)\n",
      "            print(\"*** TENSORBOARD CALLBACK {} ***\".format(tensorboard_callback))\n",
      "            callbacks.append(tensorboard_callback)\n",
      "\n",
      "        print(\"*** OPTIMIZER {} ***\".format(optimizer))\n",
      "\n",
      "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
      "        metric = tf.keras.metrics.SparseCategoricalAccuracy(\"accuracy\")\n",
      "\n",
      "        model.compile(optimizer=optimizer, loss=loss, metrics=[metric])\n",
      "        print(\"Compiled model {}\".format(model))\n",
      "        #        model.layers[0].trainable = not freeze_bert_layer\n",
      "        print(model.summary())\n",
      "\n",
      "        if run_validation:\n",
      "            validation_data_filenames = glob(os.path.join(validation_data, \"*.tfrecord\"))\n",
      "            print(\"validation_data_filenames {}\".format(validation_data_filenames))\n",
      "            validation_dataset = file_based_input_dataset_builder(\n",
      "                channel=\"validation\",\n",
      "                input_filenames=validation_data_filenames,\n",
      "                pipe_mode=pipe_mode,\n",
      "                is_training=False,\n",
      "                drop_remainder=False,\n",
      "                batch_size=validation_batch_size,\n",
      "                epochs=epochs,\n",
      "                steps_per_epoch=validation_steps,\n",
      "                max_seq_length=max_seq_length,\n",
      "            ).map(select_data_and_label_from_record)\n",
      "\n",
      "            print(\"Starting Training and Validation...\")\n",
      "            validation_dataset = validation_dataset.take(validation_steps)\n",
      "            train_and_validation_history = model.fit(\n",
      "                train_dataset,\n",
      "                shuffle=True,\n",
      "                epochs=epochs,\n",
      "                initial_epoch=initial_epoch_number,\n",
      "                steps_per_epoch=train_steps_per_epoch,\n",
      "                validation_data=validation_dataset,\n",
      "                validation_steps=validation_steps,\n",
      "                callbacks=callbacks,\n",
      "            )\n",
      "            print(train_and_validation_history)\n",
      "        else:  # Not running validation\n",
      "            print(\"Starting Training (Without Validation)...\")\n",
      "            train_history = model.fit(\n",
      "                train_dataset,\n",
      "                shuffle=True,\n",
      "                epochs=epochs,\n",
      "                initial_epoch=initial_epoch_number,\n",
      "                steps_per_epoch=train_steps_per_epoch,\n",
      "                callbacks=callbacks,\n",
      "            )\n",
      "            print(train_history)\n",
      "\n",
      "        if run_test:\n",
      "            test_data_filenames = glob(os.path.join(test_data, \"*.tfrecord\"))\n",
      "            print(\"test_data_filenames {}\".format(test_data_filenames))\n",
      "            test_dataset = file_based_input_dataset_builder(\n",
      "                channel=\"test\",\n",
      "                input_filenames=test_data_filenames,\n",
      "                pipe_mode=pipe_mode,\n",
      "                is_training=False,\n",
      "                drop_remainder=False,\n",
      "                batch_size=test_batch_size,\n",
      "                epochs=epochs,\n",
      "                steps_per_epoch=test_steps,\n",
      "                max_seq_length=max_seq_length,\n",
      "            ).map(select_data_and_label_from_record)\n",
      "\n",
      "            print(\"Starting test...\")\n",
      "            test_history = model.evaluate(test_dataset, steps=test_steps, callbacks=callbacks)\n",
      "\n",
      "            print(\"Test history {}\".format(test_history))\n",
      "\n",
      "        # Save the Fine-Yuned Transformers Model as a New \"Pre-Trained\" Model\n",
      "        print(\"transformer_fine_tuned_model_path {}\".format(transformer_fine_tuned_model_path))\n",
      "        transformer_model.save_pretrained(transformer_fine_tuned_model_path)\n",
      "        print(\"Model inputs after save_pretrained: {}\".format(model.inputs))\n",
      "\n",
      "        # Save the TensorFlow SavedModel for Serving Predictions\n",
      "        print(\"tensorflow_saved_model_path {}\".format(tensorflow_saved_model_path))\n",
      "        model.save(tensorflow_saved_model_path, include_optimizer=False, overwrite=True, save_format=\"tf\")\n",
      "\n",
      "        # Copy inference.py and requirements.txt to the code/ directory\n",
      "        #   Note: This is required for the SageMaker Endpoint to pick them up.\n",
      "        #         This appears to be hard-coded and must be called code/\n",
      "        inference_path = os.path.join(local_model_dir, \"code/\")\n",
      "        print(\"Copying inference source files to {}\".format(inference_path))\n",
      "        os.makedirs(inference_path, exist_ok=True)\n",
      "        os.system(\"cp inference.py {}\".format(inference_path))\n",
      "        print(glob(inference_path))\n",
      "        #        os.system('cp requirements.txt {}/code'.format(inference_path))\n",
      "\n",
      "        # Copy test data for the evaluation step\n",
      "        os.system(\"cp -R ./test_data/ {}\".format(local_model_dir))\n",
      "\n",
      "    if run_sample_predictions:\n",
      "\n",
      "        def predict(text):\n",
      "            encode_plus_tokens = tokenizer.encode_plus(\n",
      "                text, \n",
      "                padding='max_length', \n",
      "                max_length=max_seq_length, \n",
      "                truncation=True, \n",
      "                return_tensors=\"tf\"\n",
      "            )\n",
      "            # The id from the pre-trained BERT vocabulary that represents the token.  (Padding of 0 will be used if the # of tokens is less than `max_seq_length`)\n",
      "            input_ids = encode_plus_tokens[\"input_ids\"]\n",
      "\n",
      "            # Specifies which tokens BERT should pay attention to (0 or 1).  Padded `input_ids` will have 0 in each of these vector elements.\n",
      "            input_mask = encode_plus_tokens[\"attention_mask\"]\n",
      "\n",
      "            outputs = model.predict(x=(input_ids, input_mask))\n",
      "\n",
      "            prediction = [{\"label\": config.id2label[item.argmax()], \"score\": item.max().item()} for item in outputs]\n",
      "\n",
      "            return prediction[0][\"label\"]\n",
      "\n",
      "        print(\n",
      "            \"\"\"I loved it!  I will recommend this to everyone.\"\"\",\n",
      "            predict(\"\"\"I loved it!  I will recommend this to everyone.\"\"\"),\n",
      "        )\n",
      "\n",
      "        print(\"\"\"It's OK.\"\"\", predict(\"\"\"It's OK.\"\"\"))\n",
      "\n",
      "        print(\n",
      "            \"\"\"Really bad.  I hope they don't make this anymore.\"\"\",\n",
      "            predict(\"\"\"Really bad.  I hope they don't make this anymore.\"\"\"),\n",
      "        )\n",
      "\n",
      "        df_test_reviews = pd.read_csv(\n",
      "            \"./test_data/amazon_reviews_us_Digital_Software_v1_00.tsv.gz\",\n",
      "            delimiter=\"\\t\",\n",
      "            quoting=csv.QUOTE_NONE,\n",
      "            compression=\"gzip\",\n",
      "        )[[\"review_body\", \"star_rating\"]]\n",
      "\n",
      "        df_test_reviews = df_test_reviews.sample(n=100)\n",
      "        df_test_reviews.shape\n",
      "        df_test_reviews.head()\n",
      "\n",
      "        y_test = df_test_reviews[\"review_body\"].map(predict)\n",
      "        y_test\n",
      "\n",
      "        y_actual = df_test_reviews[\"star_rating\"]\n",
      "        y_actual\n",
      "\n",
      "        from sklearn.metrics import classification_report\n",
      "\n",
      "        print(classification_report(y_true=y_test, y_pred=y_actual))\n",
      "\n",
      "        from sklearn.metrics import accuracy_score\n",
      "\n",
      "        accuracy = accuracy_score(y_true=y_test, y_pred=y_actual)\n",
      "        print(\"Test accuracy: \", accuracy)\n",
      "\n",
      "        import matplotlib.pyplot as plt\n",
      "        import pandas as pd\n",
      "\n",
      "        def plot_conf_mat(cm, classes, title, cmap=plt.cm.Greens):\n",
      "            print(cm)\n",
      "            plt.imshow(cm, interpolation=\"nearest\", cmap=cmap)\n",
      "            plt.title(title)\n",
      "            plt.colorbar()\n",
      "            tick_marks = np.arange(len(classes))\n",
      "            plt.xticks(tick_marks, classes, rotation=45)\n",
      "            plt.yticks(tick_marks, classes)\n",
      "\n",
      "            fmt = \"d\"\n",
      "            thresh = cm.max() / 2.0\n",
      "            for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
      "                plt.text(\n",
      "                    j,\n",
      "                    i,\n",
      "                    format(cm[i, j], fmt),\n",
      "                    horizontalalignment=\"center\",\n",
      "                    color=\"black\" if cm[i, j] > thresh else \"black\",\n",
      "                )\n",
      "\n",
      "                plt.tight_layout()\n",
      "                plt.ylabel(\"True label\")\n",
      "                plt.xlabel(\"Predicted label\")\n",
      "\n",
      "        import itertools\n",
      "        import numpy as np\n",
      "        from sklearn.metrics import confusion_matrix\n",
      "        import matplotlib.pyplot as plt\n",
      "\n",
      "        cm = confusion_matrix(y_true=y_test, y_pred=y_actual)\n",
      "\n",
      "        plt.figure()\n",
      "        fig, ax = plt.subplots(figsize=(10, 5))\n",
      "        plot_conf_mat(cm, classes=[\"1\", \"2\", \"3\", \"4\", \"5\"], title=\"Confusion Matrix\")\n",
      "\n",
      "        # Save the confusion matrix\n",
      "        plt.show()\n",
      "\n",
      "        # Model Output\n",
      "        metrics_path = os.path.join(local_model_dir, \"metrics/\")\n",
      "        os.makedirs(metrics_path, exist_ok=True)\n",
      "        plt.savefig(\"{}/confusion_matrix.png\".format(metrics_path))\n",
      "\n",
      "        report_dict = {\n",
      "            \"metrics\": {\n",
      "                \"accuracy\": {\n",
      "                    \"value\": accuracy,\n",
      "                },\n",
      "            },\n",
      "        }\n",
      "\n",
      "        evaluation_path = \"{}/evaluation.json\".format(metrics_path)\n",
      "        with open(evaluation_path, \"w\") as f:\n",
      "            f.write(json.dumps(report_dict))\n"
     ]
    }
   ],
   "source": [
    "!cat src/tf_bert_reviews.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Hyper-Parameters for Classification Layer\n",
    "First, retrieve `max_seq_length` from the prepare phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    max_seq_length\n",
    "    print(\"[OK]\")\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the previous PREPARE section before you continue.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n"
     ]
    }
   ],
   "source": [
    "print(max_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "epsilon = 0.00000001\n",
    "train_batch_size = 128\n",
    "validation_batch_size = 128\n",
    "test_batch_size = 128\n",
    "train_steps_per_epoch = 100\n",
    "validation_steps = 100\n",
    "test_steps = 100\n",
    "train_instance_count = 1\n",
    "train_instance_type = \"ml.c5.4xlarge\"\n",
    "train_volume_size = 1024\n",
    "use_xla = True\n",
    "use_amp = True\n",
    "enable_sagemaker_debugger = False\n",
    "enable_checkpointing = False\n",
    "enable_tensorboard = False\n",
    "input_mode = \"File\"\n",
    "run_validation = True\n",
    "run_test = True\n",
    "run_sample_predictions = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track the Optimizations Within our Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r experiment_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiment_name\n",
    "    print(\"[OK]\")\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the previous TRAIN section before you continue.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon-Customer-Reviews-BERT-Experiment-1709436495\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r trial_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    trial_name\n",
    "    print(\"[OK]\")\n",
    "except NameError:\n",
    "    print(\"+++++++++++++++++++++++++++++++\")\n",
    "    print(\"[ERROR] Please run the notebooks in the previous TRAIN section before you continue.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial-1709436495\n"
     ]
    }
   ],
   "source": [
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fccdb22a050>,trial_name='trial-1709436495',trial_arn='arn:aws:sagemaker:us-east-1:211125778552:experiment-trial/trial-1709436495',display_name='trial-1709436495',experiment_name='Amazon-Customer-Reviews-BERT-Experiment-1709436495',creation_time=datetime.datetime(2024, 3, 3, 3, 28, 16, 49000, tzinfo=tzlocal()),created_by={'UserProfileArn': 'arn:aws:sagemaker:us-east-1:211125778552:user-profile/d-k0wihxzgpgsi/default-user', 'UserProfileName': 'default-user', 'DomainId': 'd-k0wihxzgpgsi'},last_modified_time=datetime.datetime(2024, 3, 6, 16, 51, 11, 857000, tzinfo=tzlocal()),last_modified_by={'UserProfileArn': 'arn:aws:sagemaker:us-east-1:211125778552:user-profile/d-k0wihxzgpgsi/default-user'},response_metadata={'RequestId': '15215458-f1f4-4125-bde1-bddc85d8e405', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '15215458-f1f4-4125-bde1-bddc85d8e405', 'content-type': 'application/x-amz-json-1.1', 'content-length': '587', 'date': 'Wed, 06 Mar 2024 16:51:46 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "timestamp = \"{}\".format(int(time.time()))\n",
    "\n",
    "trial = Trial.load(trial_name=trial_name)\n",
    "print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimize trial component name TrialComponent-2024-03-06-165147-drsw\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "tracker_optimize = Tracker.create(display_name=\"optimize-2\", sagemaker_boto_client=sm)\n",
    "\n",
    "optimize_trial_component_name = tracker_optimize.trial_component.trial_component_name\n",
    "print(\"Optimize trial component name {}\".format(optimize_trial_component_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach the `deploy` Trial Component and Tracker as a Component to the Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.add_trial_component(tracker_optimize.trial_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Dynamic Hyper-Parameter Ranges to Explore\n",
    "While not necessary, we can choose to statically define any hyper-parameters that we are not choosing to explore in this WarmStart optimization run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter\n",
    "from sagemaker.tuner import ContinuousParameter\n",
    "from sagemaker.tuner import CategoricalParameter\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "hyperparameter_ranges = {\n",
    "    \"learning_rate\": ContinuousParameter(0.00015, 0.00075, scaling_type=\"Linear\"),\n",
    "    \"train_batch_size\": CategoricalParameter([64, 128]),\n",
    "    \"freeze_bert_layer\": CategoricalParameter([True, False]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Track the Hyper-Parameter Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialComponent(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fcce036ddd0>,trial_component_name='TrialComponent-2024-03-06-165147-drsw',display_name='optimize-2',tags=None,trial_component_arn='arn:aws:sagemaker:us-east-1:211125778552:experiment-trial-component/TrialComponent-2024-03-06-165147-drsw',response_metadata={'RequestId': '266dc5ed-4206-4f19-89ff-9331535d7bc1', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '266dc5ed-4206-4f19-89ff-9331535d7bc1', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Wed, 06 Mar 2024 16:51:47 GMT'}, 'RetryAttempts': 0},parameters={'learning_rate': <sagemaker.parameter.ContinuousParameter object at 0x7fccda88fa10>, 'train_batch_size': <sagemaker.parameter.CategoricalParameter object at 0x7fccda88fb90>, 'freeze_bert_layer': <sagemaker.parameter.CategoricalParameter object at 0x7fccda88fb50>},input_artifacts={},output_artifacts={})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_optimize.log_parameters(hyperparameter_ranges)\n",
    "\n",
    "# must save after logging\n",
    "tracker_optimize.trial_component.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_definitions = [\n",
    "    {\"Name\": \"train:loss\", \"Regex\": \"loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \"accuracy: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation:loss\", \"Regex\": \"val_loss: ([0-9\\\\.]+)\"},\n",
    "    {\"Name\": \"validation:accuracy\", \"Regex\": \"val_accuracy: ([0-9\\\\.]+)\"},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "estimator = TensorFlow(\n",
    "    entry_point=\"tf_bert_reviews.py\",\n",
    "    source_dir=\"src\",\n",
    "    role=role,\n",
    "    instance_count=train_instance_count,  # Make sure you have at least this number of input files or the ShardedByS3Key distibution strategy will fail the job due to no data available\n",
    "    instance_type=train_instance_type,\n",
    "    volume_size=train_volume_size,\n",
    "    py_version=\"py37\",\n",
    "    framework_version=\"2.3.1\",\n",
    "    hyperparameters={\n",
    "        \"epochs\": epochs,\n",
    "        \"epsilon\": epsilon,\n",
    "        \"validation_batch_size\": validation_batch_size,\n",
    "        \"test_batch_size\": test_batch_size,\n",
    "        \"train_steps_per_epoch\": train_steps_per_epoch,\n",
    "        \"validation_steps\": validation_steps,\n",
    "        \"test_steps\": test_steps,\n",
    "        \"use_xla\": use_xla,\n",
    "        \"use_amp\": use_amp,\n",
    "        \"max_seq_length\": max_seq_length,\n",
    "        \"enable_sagemaker_debugger\": enable_sagemaker_debugger,\n",
    "        \"enable_checkpointing\": enable_checkpointing,\n",
    "        \"enable_tensorboard\": enable_tensorboard,\n",
    "        \"run_validation\": run_validation,\n",
    "        \"run_test\": run_test,\n",
    "        \"run_sample_predictions\": run_sample_predictions,\n",
    "    },\n",
    "    input_mode=input_mode,\n",
    "    metric_definitions=metrics_definitions,\n",
    "    #                       max_run=7200 # max 2 hours * 60 minutes seconds per hour * 60 seconds per minute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Warm Start Config\n",
    "We configure `WarmStartConfig` using 1 or more  of the previous hyper-parameter tuning job runs called the `parent` jobs - as well as a `WarmStartType`.  The parents must have finished either with one of the following success or failure states: `Completed`, `Stopped`, or `Failed`.\n",
    "\n",
    "`WarmStartType` is one of the following strategies:\n",
    "\n",
    "* `IDENTICAL_DATA_AND_ALGORITHM` uses the same input data and algorithm as the parent tuning jobs, but allows a practitioner to explore more hyper-parameter range values.  Upon completion, a tuning job with this strategy will return an additional field, `OverallBestTrainingJob` containing the best model candidate including this tuning job as well as the completed parent tuning jobs.\n",
    "* `TRANSFER_LEARNING` allows you to transfer the knowledge from previous tuning jobs.  You can use different input dataset and algorithm - as well as everything from the `IDENTICAL_DATA_AND_ALGORITHM` strategy.\n",
    "\n",
    "_Note:  Recursive parent-child relationships are not supported._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous Tuning Job Name: tensorflow-training-240306-1631\n"
     ]
    }
   ],
   "source": [
    "print(\"Previous Tuning Job Name: {}\".format(tuning_job_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import WarmStartConfig\n",
    "from sagemaker.tuner import WarmStartTypes\n",
    "\n",
    "warm_start_config = WarmStartConfig(\n",
    "    warm_start_type=WarmStartTypes.IDENTICAL_DATA_AND_ALGORITHM, parents={tuning_job_name}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup HyperparameterTuner with Warm Start Config including New Hyper-Parameter Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_metric_name = \"train:accuracy\"\n",
    "\n",
    "tuner = HyperparameterTuner(\n",
    "    estimator=estimator,\n",
    "    objective_type=\"Maximize\",\n",
    "    objective_metric_name=objective_metric_name,\n",
    "    hyperparameter_ranges=hyperparameter_ranges,\n",
    "    metric_definitions=metrics_definitions,\n",
    "    max_jobs=2,\n",
    "    max_parallel_jobs=1,\n",
    "    strategy=\"Bayesian\",\n",
    "    early_stopping_type=\"Auto\",\n",
    "    warm_start_config=warm_start_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:Defaulting to the only supported framework/algorithm version: latest.\n",
      "INFO:sagemaker.image_uris:Ignoring unnecessary instance type: None.\n",
      "INFO:sagemaker:Creating hyperparameter tuning job with name: tensorflow-training-240306-1651\n"
     ]
    }
   ],
   "source": [
    "tuner.fit(\n",
    "    {\"train\": s3_input_train_data, \"validation\": s3_input_validation_data, \"test\": s3_input_test_data},\n",
    "    include_cls_metadata=False,\n",
    "    wait=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# If You See an Error, Please Wait for the Hyper-Parameter Tuning Job to Complete from the Previous Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Check Tuning Job Status\n",
    "\n",
    "Re-run this cell to track the status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "InProgress\n",
      "\n",
      "\n",
      "{'ConsumedResources': {'RuntimeInSeconds': 0},\n",
      " 'CreationTime': datetime.datetime(2024, 3, 6, 16, 51, 50, 138000, tzinfo=tzlocal()),\n",
      " 'HyperParameterTuningJobArn': 'arn:aws:sagemaker:us-east-1:211125778552:hyper-parameter-tuning-job/tensorflow-training-240306-1651',\n",
      " 'HyperParameterTuningJobConfig': {'HyperParameterTuningJobObjective': {'MetricName': 'train:accuracy',\n",
      "                                                                        'Type': 'Maximize'},\n",
      "                                   'ParameterRanges': {'CategoricalParameterRanges': [{'Name': 'train_batch_size',\n",
      "                                                                                       'Values': ['\"64\"',\n",
      "                                                                                                  '\"128\"']},\n",
      "                                                                                      {'Name': 'freeze_bert_layer',\n",
      "                                                                                       'Values': ['\"True\"',\n",
      "                                                                                                  '\"False\"']}],\n",
      "                                                       'ContinuousParameterRanges': [{'MaxValue': '0.00075',\n",
      "                                                                                      'MinValue': '0.00015',\n",
      "                                                                                      'Name': 'learning_rate',\n",
      "                                                                                      'ScalingType': 'Linear'}],\n",
      "                                                       'IntegerParameterRanges': []},\n",
      "                                   'ResourceLimits': {'MaxNumberOfTrainingJobs': 2,\n",
      "                                                      'MaxParallelTrainingJobs': 1},\n",
      "                                   'Strategy': 'Bayesian',\n",
      "                                   'TrainingJobEarlyStoppingType': 'Auto'},\n",
      " 'HyperParameterTuningJobName': 'tensorflow-training-240306-1651',\n",
      " 'HyperParameterTuningJobStatus': 'InProgress',\n",
      " 'LastModifiedTime': datetime.datetime(2024, 3, 6, 16, 51, 50, 503000, tzinfo=tzlocal()),\n",
      " 'ObjectiveStatusCounters': {'Failed': 0, 'Pending': 0, 'Succeeded': 0},\n",
      " 'ResponseMetadata': {'HTTPHeaders': {'content-length': '4075',\n",
      "                                      'content-type': 'application/x-amz-json-1.1',\n",
      "                                      'date': 'Wed, 06 Mar 2024 16:51:50 GMT',\n",
      "                                      'x-amzn-requestid': '0c782008-1814-4319-a185-d85d14959743'},\n",
      "                      'HTTPStatusCode': 200,\n",
      "                      'RequestId': '0c782008-1814-4319-a185-d85d14959743',\n",
      "                      'RetryAttempts': 0},\n",
      " 'TrainingJobDefinition': {'AlgorithmSpecification': {'MetricDefinitions': [{'Name': 'train:loss',\n",
      "                                                                             'Regex': 'loss: '\n",
      "                                                                                      '([0-9\\\\.]+)'},\n",
      "                                                                            {'Name': 'train:accuracy',\n",
      "                                                                             'Regex': 'accuracy: '\n",
      "                                                                                      '([0-9\\\\.]+)'},\n",
      "                                                                            {'Name': 'validation:loss',\n",
      "                                                                             'Regex': 'val_loss: '\n",
      "                                                                                      '([0-9\\\\.]+)'},\n",
      "                                                                            {'Name': 'validation:accuracy',\n",
      "                                                                             'Regex': 'val_accuracy: '\n",
      "                                                                                      '([0-9\\\\.]+)'},\n",
      "                                                                            {'Name': 'ObjectiveMetric',\n",
      "                                                                             'Regex': 'accuracy: '\n",
      "                                                                                      '([0-9\\\\.]+)'}],\n",
      "                                                      'TrainingImage': '763104351884.dkr.ecr.us-east-1.amazonaws.com/tensorflow-training:2.3.1-cpu-py37',\n",
      "                                                      'TrainingInputMode': 'File'},\n",
      "                           'EnableInterContainerTrafficEncryption': False,\n",
      "                           'EnableManagedSpotTraining': False,\n",
      "                           'EnableNetworkIsolation': False,\n",
      "                           'InputDataConfig': [{'ChannelName': 'train',\n",
      "                                                'DataSource': {'S3DataSource': {'S3DataDistributionType': 'ShardedByS3Key',\n",
      "                                                                                'S3DataType': 'S3Prefix',\n",
      "                                                                                'S3Uri': 's3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-train'}}},\n",
      "                                               {'ChannelName': 'validation',\n",
      "                                                'DataSource': {'S3DataSource': {'S3DataDistributionType': 'ShardedByS3Key',\n",
      "                                                                                'S3DataType': 'S3Prefix',\n",
      "                                                                                'S3Uri': 's3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-validation'}}},\n",
      "                                               {'ChannelName': 'test',\n",
      "                                                'DataSource': {'S3DataSource': {'S3DataDistributionType': 'ShardedByS3Key',\n",
      "                                                                                'S3DataType': 'S3Prefix',\n",
      "                                                                                'S3Uri': 's3://sagemaker-us-east-1-211125778552/sagemaker-scikit-learn-2024-03-03-03-46-55-548/output/bert-test'}}}],\n",
      "                           'OutputDataConfig': {'S3OutputPath': 's3://sagemaker-us-east-1-211125778552/'},\n",
      "                           'ResourceConfig': {'InstanceCount': 1,\n",
      "                                              'InstanceType': 'ml.c5.4xlarge',\n",
      "                                              'VolumeSizeInGB': 1024},\n",
      "                           'RoleArn': 'arn:aws:iam::211125778552:role/service-role/AmazonSageMaker-ExecutionRole-20240215T152311',\n",
      "                           'StaticHyperParameters': {'_tuning_objective_metric': 'train:accuracy',\n",
      "                                                     'enable_checkpointing': 'false',\n",
      "                                                     'enable_sagemaker_debugger': 'false',\n",
      "                                                     'enable_tensorboard': 'false',\n",
      "                                                     'epochs': '1',\n",
      "                                                     'epsilon': '1e-08',\n",
      "                                                     'max_seq_length': '64',\n",
      "                                                     'model_dir': '\"s3://sagemaker-us-east-1-211125778552/tensorflow-training-2024-03-06-16-51-48-420/model\"',\n",
      "                                                     'run_sample_predictions': 'true',\n",
      "                                                     'run_test': 'true',\n",
      "                                                     'run_validation': 'true',\n",
      "                                                     'sagemaker_container_log_level': '20',\n",
      "                                                     'sagemaker_estimator_class_name': '\"TensorFlow\"',\n",
      "                                                     'sagemaker_estimator_module': '\"sagemaker.tensorflow.estimator\"',\n",
      "                                                     'sagemaker_job_name': '\"tensorflow-training-2024-03-06-16-51-48-420\"',\n",
      "                                                     'sagemaker_program': '\"tf_bert_reviews.py\"',\n",
      "                                                     'sagemaker_region': '\"us-east-1\"',\n",
      "                                                     'sagemaker_submit_directory': '\"s3://sagemaker-us-east-1-211125778552/tensorflow-training-2024-03-06-16-51-48-420/source/sourcedir.tar.gz\"',\n",
      "                                                     'test_batch_size': '128',\n",
      "                                                     'test_steps': '100',\n",
      "                                                     'train_steps_per_epoch': '100',\n",
      "                                                     'use_amp': 'true',\n",
      "                                                     'use_xla': 'true',\n",
      "                                                     'validation_batch_size': '128',\n",
      "                                                     'validation_steps': '100'},\n",
      "                           'StoppingCondition': {'MaxRuntimeInSeconds': 86400}},\n",
      " 'TrainingJobStatusCounters': {'Completed': 0,\n",
      "                               'InProgress': 0,\n",
      "                               'NonRetryableError': 0,\n",
      "                               'RetryableError': 0,\n",
      "                               'Stopped': 0},\n",
      " 'WarmStartConfig': {'ParentHyperParameterTuningJobs': [{'HyperParameterTuningJobName': 'tensorflow-training-240306-1631'}],\n",
      "                     'WarmStartType': 'IdenticalDataAndAlgorithm'}}\n",
      "Not yet complete, but 0 jobs have completed.\n",
      "No training jobs have reported results yet.\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "tuning_job_name = tuner.latest_tuning_job.job_name\n",
    "\n",
    "job_description = sm.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName=tuning_job_name)\n",
    "\n",
    "status = job_description[\"HyperParameterTuningJobStatus\"]\n",
    "\n",
    "print(\"\\n\")\n",
    "print(status)\n",
    "print(\"\\n\")\n",
    "pprint(job_description)\n",
    "\n",
    "if status != \"Completed\":\n",
    "    job_count = job_description[\"TrainingJobStatusCounters\"][\"Completed\"]\n",
    "    print(\"Not yet complete, but {} jobs have completed.\".format(job_count))\n",
    "\n",
    "    if job_description.get(\"BestTrainingJob\", None):\n",
    "        print(\"Best candidate:\")\n",
    "        pprint(job_description[\"BestTrainingJob\"][\"TrainingJobName\"])\n",
    "        pprint(job_description[\"BestTrainingJob\"][\"FinalHyperParameterTuningJobObjectiveMetric\"])\n",
    "    else:\n",
    "        print(\"No training jobs have reported results yet.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/hyper-tuning-jobs/tensorflow-training-240306-1651\">Hyper-Parameter Tuning Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/hyper-tuning-jobs/{}\">Hyper-Parameter Tuning Job</a></b>'.format(\n",
    "            region, tuning_job_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Please Wait for the ^^ Tuning Job ^^ to Complete Above_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".....................................................................................................................................................................................................................................................................................!\n"
     ]
    }
   ],
   "source": [
    "tuner.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the Tuning Job\n",
    "### _Note:  This will fail at first.  Please wait about 15-30 seconds and re-run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 9)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import HyperparameterTuningJobAnalytics\n",
    "\n",
    "hp_results = HyperparameterTuningJobAnalytics(sagemaker_session=sess, hyperparameter_tuning_job_name=tuning_job_name)\n",
    "\n",
    "df_results = hp_results.dataframe()\n",
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freeze_bert_layer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"False\"</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>\"128\"</td>\n",
       "      <td>tensorflow-training-240306-1651-002-2601ee0c</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>2024-03-06 17:06:45+00:00</td>\n",
       "      <td>2024-03-06 17:15:28+00:00</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"False\"</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>\"64\"</td>\n",
       "      <td>tensorflow-training-240306-1651-001-3233e475</td>\n",
       "      <td>Completed</td>\n",
       "      <td>0.2959</td>\n",
       "      <td>2024-03-06 16:52:42+00:00</td>\n",
       "      <td>2024-03-06 17:04:25+00:00</td>\n",
       "      <td>703.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  freeze_bert_layer  learning_rate train_batch_size  \\\n",
       "0           \"False\"       0.000189            \"128\"   \n",
       "1           \"False\"       0.000342             \"64\"   \n",
       "\n",
       "                                TrainingJobName TrainingJobStatus  \\\n",
       "0  tensorflow-training-240306-1651-002-2601ee0c           Stopped   \n",
       "1  tensorflow-training-240306-1651-001-3233e475         Completed   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0               0.3843 2024-03-06 17:06:45+00:00 2024-03-06 17:15:28+00:00   \n",
       "1               0.2959 2024-03-06 16:52:42+00:00 2024-03-06 17:04:25+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                       523.0  \n",
       "1                       703.0  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(\"FinalObjectiveValue\", ascending=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show the Overall Best Candidate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freeze_bert_layer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>TrainingJobName</th>\n",
       "      <th>TrainingJobStatus</th>\n",
       "      <th>FinalObjectiveValue</th>\n",
       "      <th>TrainingStartTime</th>\n",
       "      <th>TrainingEndTime</th>\n",
       "      <th>TrainingElapsedTimeSeconds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"False\"</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>\"128\"</td>\n",
       "      <td>tensorflow-training-240306-1651-002-2601ee0c</td>\n",
       "      <td>Stopped</td>\n",
       "      <td>0.3843</td>\n",
       "      <td>2024-03-06 17:06:45+00:00</td>\n",
       "      <td>2024-03-06 17:15:28+00:00</td>\n",
       "      <td>523.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  freeze_bert_layer  learning_rate train_batch_size  \\\n",
       "0           \"False\"       0.000189            \"128\"   \n",
       "\n",
       "                                TrainingJobName TrainingJobStatus  \\\n",
       "0  tensorflow-training-240306-1651-002-2601ee0c           Stopped   \n",
       "\n",
       "   FinalObjectiveValue         TrainingStartTime           TrainingEndTime  \\\n",
       "0               0.3843 2024-03-06 17:06:45+00:00 2024-03-06 17:15:28+00:00   \n",
       "\n",
       "   TrainingElapsedTimeSeconds  \n",
       "0                       523.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.sort_values(\"FinalObjectiveValue\", ascending=0).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_candidate_tuning_job_name = df_results.sort_values(\"FinalObjectiveValue\", ascending=0).head(1)[\"TrainingJobName\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log the Best Hyper-Parameter and Objective Metric in the Experiment\n",
    "\n",
    "Logging `learning_rate` parameter and `accuracy` metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.000189\n",
      "Name: learning_rate, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_learning_rate = df_results.sort_values(\"FinalObjectiveValue\", ascending=0).head(1)[\"learning_rate\"]\n",
    "print(best_learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.3843\n",
      "Name: FinalObjectiveValue, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "best_accuracy = df_results.sort_values(\"FinalObjectiveValue\", ascending=0).head(1)[\"FinalObjectiveValue\"]\n",
    "print(best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialComponent(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fcce036ddd0>,trial_component_name='TrialComponent-2024-03-06-165147-drsw',display_name='optimize-2',tags=None,trial_component_arn='arn:aws:sagemaker:us-east-1:211125778552:experiment-trial-component/TrialComponent-2024-03-06-165147-drsw',response_metadata={'RequestId': '9383cbed-9861-445e-b0ff-c0fcf48d2632', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9383cbed-9861-445e-b0ff-c0fcf48d2632', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Wed, 06 Mar 2024 17:15:32 GMT'}, 'RetryAttempts': 0},parameters={'learning_rate': 0.00018922006661625286, 'train_batch_size': <sagemaker.parameter.CategoricalParameter object at 0x7fccda88fb90>, 'freeze_bert_layer': <sagemaker.parameter.CategoricalParameter object at 0x7fccda88fb50>},input_artifacts={},output_artifacts={})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_optimize.log_parameters({\"learning_rate\": float(best_learning_rate)})\n",
    "\n",
    "# must save after logging\n",
    "tracker_optimize.trial_component.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialComponent(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fcce036ddd0>,trial_component_name='TrialComponent-2024-03-06-165147-drsw',display_name='optimize-2',tags=None,trial_component_arn='arn:aws:sagemaker:us-east-1:211125778552:experiment-trial-component/TrialComponent-2024-03-06-165147-drsw',response_metadata={'RequestId': '3d206742-c5ff-402d-8e9d-24203cc6ac0d', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '3d206742-c5ff-402d-8e9d-24203cc6ac0d', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Wed, 06 Mar 2024 17:15:32 GMT'}, 'RetryAttempts': 0},parameters={'learning_rate': 0.00018922006661625286, 'train_batch_size': <sagemaker.parameter.CategoricalParameter object at 0x7fccda88fb90>, 'freeze_bert_layer': <sagemaker.parameter.CategoricalParameter object at 0x7fccda88fb50>},input_artifacts={},output_artifacts={})"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_optimize.log_metric(\"accuracy\", float(best_accuracy))\n",
    "\n",
    "tracker_optimize.trial_component.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## _Ignore any ^^ ERROR above ^^. This is OK._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Experiment Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 71)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=sess,\n",
    "    experiment_name=experiment_name,\n",
    "    metric_names=[\"validation:accuracy\"],\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Descending\",\n",
    ")\n",
    "\n",
    "lineage_df = lineage_table.dataframe()\n",
    "lineage_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>freeze_bert_layer</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>train_batch_size</th>\n",
       "      <th>Trials</th>\n",
       "      <th>Experiments</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.InstanceCount</th>\n",
       "      <th>SageMaker.InstanceType</th>\n",
       "      <th>...</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>AWS_DEFAULT_REGION</th>\n",
       "      <th>raw-input-data - MediaType</th>\n",
       "      <th>raw-input-data - Value</th>\n",
       "      <th>bert-test - MediaType</th>\n",
       "      <th>bert-test - Value</th>\n",
       "      <th>bert-train - MediaType</th>\n",
       "      <th>bert-train - Value</th>\n",
       "      <th>bert-validation - MediaType</th>\n",
       "      <th>bert-validation - Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrialComponent-2024-03-06-165147-drsw</td>\n",
       "      <td>optimize-2</td>\n",
       "      <td>&lt;sagemaker.parameter.CategoricalParameter obje...</td>\n",
       "      <td>&lt;sagemaker.parameter.ContinuousParameter objec...</td>\n",
       "      <td>&lt;sagemaker.parameter.CategoricalParameter obje...</td>\n",
       "      <td>[trial-1709436495]</td>\n",
       "      <td>[Amazon-Customer-Reviews-BERT-Experiment-17094...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TrialComponent-2024-03-06-163102-dwoe</td>\n",
       "      <td>optimize-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[trial-1709436495]</td>\n",
       "      <td>[Amazon-Customer-Reviews-BERT-Experiment-17094...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sagemaker-scikit-learn-2024-03-06-15-39-19-291...</td>\n",
       "      <td>evaluate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[trial-1709436495]</td>\n",
       "      <td>[Amazon-Customer-Reviews-BERT-Experiment-17094...</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:211125778552:proce...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.m5.xlarge</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensorflow-training-2024-03-03-04-02-13-539-aw...</td>\n",
       "      <td>train</td>\n",
       "      <td>false</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>128.0</td>\n",
       "      <td>[trial-1709436495]</td>\n",
       "      <td>[Amazon-Customer-Reviews-BERT-Experiment-17094...</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:211125778552:train...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ml.c4.2xlarge</td>\n",
       "      <td>...</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/tensorfl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sagemaker-scikit-learn-2024-03-03-03-46-55-548...</td>\n",
       "      <td>prepare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[trial-1709436495]</td>\n",
       "      <td>[Amazon-Customer-Reviews-BERT-Experiment-17094...</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:211125778552:proce...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ml.c5.2xlarge</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us-east-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/amazon-r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/sagemake...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>sagemaker-scikit-learn-2024-03-03-03-28-16-715...</td>\n",
       "      <td>prepare</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[trial-1709436495]</td>\n",
       "      <td>[Amazon-Customer-Reviews-BERT-Experiment-17094...</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:211125778552:proce...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>ml.t3.medium</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>us-east-1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/amazon-r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-211125778552/sagemake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName DisplayName  \\\n",
       "0              TrialComponent-2024-03-06-165147-drsw  optimize-2   \n",
       "1              TrialComponent-2024-03-06-163102-dwoe  optimize-1   \n",
       "2  sagemaker-scikit-learn-2024-03-06-15-39-19-291...    evaluate   \n",
       "3  tensorflow-training-2024-03-03-04-02-13-539-aw...       train   \n",
       "4  sagemaker-scikit-learn-2024-03-03-03-46-55-548...     prepare   \n",
       "5  sagemaker-scikit-learn-2024-03-03-03-28-16-715...     prepare   \n",
       "\n",
       "                                   freeze_bert_layer  \\\n",
       "0  <sagemaker.parameter.CategoricalParameter obje...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                              false   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                       learning_rate  \\\n",
       "0  <sagemaker.parameter.ContinuousParameter objec...   \n",
       "1                                           0.000015   \n",
       "2                                                NaN   \n",
       "3                                            0.00001   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "\n",
       "                                    train_batch_size              Trials  \\\n",
       "0  <sagemaker.parameter.CategoricalParameter obje...  [trial-1709436495]   \n",
       "1                                                NaN  [trial-1709436495]   \n",
       "2                                                NaN  [trial-1709436495]   \n",
       "3                                              128.0  [trial-1709436495]   \n",
       "4                                                NaN  [trial-1709436495]   \n",
       "5                                                NaN  [trial-1709436495]   \n",
       "\n",
       "                                         Experiments  \\\n",
       "0  [Amazon-Customer-Reviews-BERT-Experiment-17094...   \n",
       "1  [Amazon-Customer-Reviews-BERT-Experiment-17094...   \n",
       "2  [Amazon-Customer-Reviews-BERT-Experiment-17094...   \n",
       "3  [Amazon-Customer-Reviews-BERT-Experiment-17094...   \n",
       "4  [Amazon-Customer-Reviews-BERT-Experiment-17094...   \n",
       "5  [Amazon-Customer-Reviews-BERT-Experiment-17094...   \n",
       "\n",
       "                                           SourceArn  SageMaker.InstanceCount  \\\n",
       "0                                                NaN                      NaN   \n",
       "1                                                NaN                      NaN   \n",
       "2  arn:aws:sagemaker:us-east-1:211125778552:proce...                      1.0   \n",
       "3  arn:aws:sagemaker:us-east-1:211125778552:train...                      1.0   \n",
       "4  arn:aws:sagemaker:us-east-1:211125778552:proce...                      2.0   \n",
       "5  arn:aws:sagemaker:us-east-1:211125778552:proce...                      2.0   \n",
       "\n",
       "  SageMaker.InstanceType  ...  \\\n",
       "0                    NaN  ...   \n",
       "1                    NaN  ...   \n",
       "2           ml.m5.xlarge  ...   \n",
       "3          ml.c4.2xlarge  ...   \n",
       "4          ml.c5.2xlarge  ...   \n",
       "5           ml.t3.medium  ...   \n",
       "\n",
       "                     SageMaker.ModelArtifact - Value  AWS_DEFAULT_REGION  \\\n",
       "0                                                NaN                 NaN   \n",
       "1                                                NaN                 NaN   \n",
       "2                                                NaN                 NaN   \n",
       "3  s3://sagemaker-us-east-1-211125778552/tensorfl...                 NaN   \n",
       "4                                                NaN           us-east-1   \n",
       "5                                                NaN           us-east-1   \n",
       "\n",
       "  raw-input-data - MediaType  \\\n",
       "0                        NaN   \n",
       "1                        NaN   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "5                        NaN   \n",
       "\n",
       "                              raw-input-data - Value bert-test - MediaType  \\\n",
       "0                                                NaN                   NaN   \n",
       "1                                                NaN                   NaN   \n",
       "2                                                NaN                   NaN   \n",
       "3                                                NaN                   NaN   \n",
       "4  s3://sagemaker-us-east-1-211125778552/amazon-r...                   NaN   \n",
       "5  s3://sagemaker-us-east-1-211125778552/amazon-r...                   NaN   \n",
       "\n",
       "                                   bert-test - Value bert-train - MediaType  \\\n",
       "0                                                NaN                    NaN   \n",
       "1                                                NaN                    NaN   \n",
       "2                                                NaN                    NaN   \n",
       "3                                                NaN                    NaN   \n",
       "4  s3://sagemaker-us-east-1-211125778552/sagemake...                    NaN   \n",
       "5  s3://sagemaker-us-east-1-211125778552/sagemake...                    NaN   \n",
       "\n",
       "                                  bert-train - Value  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4  s3://sagemaker-us-east-1-211125778552/sagemake...   \n",
       "5  s3://sagemaker-us-east-1-211125778552/sagemake...   \n",
       "\n",
       "  bert-validation - MediaType  \\\n",
       "0                         NaN   \n",
       "1                         NaN   \n",
       "2                         NaN   \n",
       "3                         NaN   \n",
       "4                         NaN   \n",
       "5                         NaN   \n",
       "\n",
       "                             bert-validation - Value  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  s3://sagemaker-us-east-1-211125778552/sagemake...  \n",
       "5  s3://sagemaker-us-east-1-211125778552/sagemake...  \n",
       "\n",
       "[6 rows x 71 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass `tuning_job_name` to the Next Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    tensorflow-training-240306-1651-002-2601ee0c\n",
      "Name: TrainingJobName, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(best_candidate_tuning_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'best_candidate_tuning_job_name' (Series)\n"
     ]
    }
   ],
   "source": [
    "%store best_candidate_tuning_job_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "autopilot_endpoint_arn                                -> 'arn:aws:sagemaker:us-east-1:211125778552:endpoint\n",
      "autopilot_model_arn                                   -> 'arn:aws:sagemaker:us-east-1:211125778552:model/au\n",
      "autopilot_train_s3_uri                                -> 's3://sagemaker-us-east-1-211125778552/data/amazon\n",
      "balance_dataset                                       -> True\n",
      "balanced_bias_data_jsonlines_s3_uri                   -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "balanced_bias_data_s3_uri                             -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "best_candidate_tuning_job_name                        -> 0    tensorflow-training-240306-1651-002-2601ee0c\n",
      "\n",
      "bias_data_s3_uri                                      -> 's3://sagemaker-us-east-1-211125778552/bias-detect\n",
      "comprehend_endpoint_arn                               -> 'arn:aws:comprehend:us-east-1:211125778552:documen\n",
      "comprehend_train_s3_uri                               -> 's3://sagemaker-us-east-1-211125778552/data/amazon\n",
      "comprehend_training_job_arn                           -> 'arn:aws:comprehend:us-east-1:211125778552:documen\n",
      "experiment_name                                       -> 'Amazon-Customer-Reviews-BERT-Experiment-170943649\n",
      "feature_group_name                                    -> 'reviews-feature-group-1709436496'\n",
      "feature_store_offline_prefix                          -> 'reviews-feature-store-1709436496'\n",
      "ingest_create_athena_db_passed                        -> True\n",
      "ingest_create_athena_table_parquet_passed             -> True\n",
      "ingest_create_athena_table_tsv_passed                 -> True\n",
      "max_seq_length                                        -> 64\n",
      "processed_metrics_s3_uri                              -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processed_test_data_s3_uri                            -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processed_train_data_s3_uri                           -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processed_validation_data_s3_uri                      -> 's3://sagemaker-us-east-1-211125778552/sagemaker-s\n",
      "processing_evaluation_metrics_job_name                -> 'sagemaker-scikit-learn-2024-03-06-15-39-19-291'\n",
      "raw_input_data_s3_uri                                 -> 's3://sagemaker-us-east-1-211125778552/amazon-revi\n",
      "s3_private_path_tsv                                   -> 's3://sagemaker-us-east-1-211125778552/amazon-revi\n",
      "s3_public_path_tsv                                    -> 's3://dsoaws/amazon-reviews-pds/tsv'\n",
      "setup_dependencies_passed                             -> True\n",
      "setup_iam_roles_passed                                -> True\n",
      "setup_s3_bucket_passed                                -> True\n",
      "test_data_bias_s3_uri                                 -> 's3://sagemaker-us-east-1-211125778552/bias/test_d\n",
      "test_data_explainablity_s3_uri                        -> 's3://sagemaker-us-east-1-211125778552/bias/test_d\n",
      "test_split_percentage                                 -> 0.2\n",
      "train_split_percentage                                -> 0.6\n",
      "training_job_name                                     -> 'tensorflow-training-2024-03-03-04-02-13-539'\n",
      "transformer_pytorch_model_dir_s3_uri                  -> 's3://sagemaker-us-east-1-211125778552/model/tenso\n",
      "trial_name                                            -> 'trial-1709436495'\n",
      "tuning_job_name                                       -> 'tensorflow-training-240306-1631'\n",
      "validation_split_percentage                           -> 0.2\n"
     ]
    }
   ],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\n    Jupyter.notebook.save_checkpoint();\n    Jupyter.notebook.session.delete();\n}\ncatch(err) {\n    // NoOp\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "data_science_on_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
