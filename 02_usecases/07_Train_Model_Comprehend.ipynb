{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Amazon Comprehend Custom Classifier Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/comprehend.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that Amazon Comprehend is currently only supported in a subset of regions: \n",
    "\n",
    "* US East (N. Virginia), US East (Ohio), US West (Oregon)\n",
    "* Canada (Central)\n",
    "* Europe (London), Europe (Ireland), Europe (Frankfurt)\n",
    "* Asia Pacific (Mumbai), Asia Pacific (Seoul), Asia Pacific (Tokyo), Asia Pacific (Singapore), Asia Pacific (Sydney)\n",
    "\n",
    "You can check https://aws.amazon.com/about-aws/global-infrastructure/regional-product-services/ for details and updates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "from botocore.config import Config\n",
    "\n",
    "config = Config(retries={\"max_attempts\": 10, \"mode\": \"adaptive\"})\n",
    "\n",
    "iam = boto3.client(\"iam\", config=config)\n",
    "sm = boto3.Session().client(service_name=\"sagemaker\", region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if you current regions supports Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [OK] COMPREHEND IS SUPPORTED IN us-east-1\n",
      " [OK] Please proceed with this notebook.\n"
     ]
    }
   ],
   "source": [
    "if region in [\n",
    "    \"ap-south-1\",\n",
    "    \"eu-west-2\",\n",
    "    \"eu-west-1\",\n",
    "    \"ap-northeast-2\",\n",
    "    \"ap-northeast-1\",\n",
    "    \"ca-central-1\",\n",
    "    \"ap-southeast-1\",\n",
    "    \"ap-southeast-2\",\n",
    "    \"eu-central-1\",\n",
    "    \"us-east-1\",\n",
    "    \"us-east-2\",\n",
    "    \"us-west-2\",\n",
    "]:\n",
    "    print(\" [OK] COMPREHEND IS SUPPORTED IN {}\".format(region))\n",
    "    print(\" [OK] Please proceed with this notebook.\")\n",
    "else:\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")\n",
    "    print(\" [ERROR] COMPREHEND IS NOT YET SUPPORTED IN {}.\".format(region))\n",
    "    print(\" [INFO] This is OK. Skip this notebook and continue with the next use case.\")\n",
    "    print(\" [INFO] This notebook is not required for the rest of this workshop.\")\n",
    "    print(\"+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comprehend = boto3.client(\"comprehend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve S3 location of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r comprehend_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not comprehend_train_s3_uri:\n",
    "    print(\"****************************************************************************************\")\n",
    "    print(\"**************** PLEASE RE-RUN THE PREVIOUS DATA PREPARATION NOTEBOOK ******************\")\n",
    "    print(\"**************** THIS NOTEBOOK WILL NOT RUN PROPERLY ***********************************\")\n",
    "    print(\"****************************************************************************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "print(comprehend_train_s3_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-02-15 23:27:40     397534 amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $comprehend_train_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See our prepared training data which we use as input for Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-211125778552/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv to tmp/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp $comprehend_train_s3_uri ./tmp/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Works great for the Federal. But I had to mail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>The bit defender antivirus plus is great!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Basically, I paid for the ability to download ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Longtime user. Would give 5 stars to the 2002-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Quicken for Mac 2015 is a nice idea, but it's ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                                  1\n",
       "0  3  Works great for the Federal. But I had to mail...\n",
       "1  5          The bit defender antivirus plus is great!\n",
       "2  2  Basically, I paid for the ability to download ...\n",
       "3  3  Longtime user. Would give 5 stars to the 2002-...\n",
       "4  2  Quicken for Mac 2015 is a nice idea, but it's ..."
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "df = pd.read_csv(\"./tmp/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Access Role for Comprehend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assume_role_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\"Effect\": \"Allow\", \"Principal\": {\"Service\": \"comprehend.amazonaws.com\"}, \"Action\": \"sts:AssumeRole\"}\n",
    "    ],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Role and Attach Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_comprehend_role_name = \"DSOAWS_Comprehend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "try:\n",
    "    iam_role_comprehend = iam.create_role(\n",
    "        RoleName=iam_comprehend_role_name,\n",
    "        AssumeRolePolicyDocument=json.dumps(assume_role_policy_doc),\n",
    "        Description=\"DSOAWS Comprehend Role\",\n",
    "    )\n",
    "except ClientError as e:\n",
    "    if e.response[\"Error\"][\"Code\"] == \"EntityAlreadyExists\":\n",
    "        iam_role_comprehend = iam.get_role(RoleName=iam_comprehend_role_name)\n",
    "        print(\"Role already exists\")\n",
    "    else:\n",
    "        print(\"Unexpected error: %s\" % e)\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Version': '2012-10-17', 'Statement': [{'Action': ['s3:GetObject'], 'Resource': ['arn:aws:s3:::sagemaker-us-east-1-211125778552/*'], 'Effect': 'Allow'}, {'Action': ['s3:ListBucket'], 'Resource': ['arn:aws:s3:::sagemaker-us-east-1-211125778552'], 'Effect': 'Allow'}, {'Action': ['s3:PutObject'], 'Resource': ['arn:aws:s3:::sagemaker-us-east-1-211125778552/*'], 'Effect': 'Allow'}]}\n"
     ]
    }
   ],
   "source": [
    "comprehend_s3_policy_doc = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\"Action\": [\"s3:GetObject\"], \"Resource\": [\"arn:aws:s3:::{}/*\".format(bucket)], \"Effect\": \"Allow\"},\n",
    "        {\"Action\": [\"s3:ListBucket\"], \"Resource\": [\"arn:aws:s3:::{}\".format(bucket)], \"Effect\": \"Allow\"},\n",
    "        {\"Action\": [\"s3:PutObject\"], \"Resource\": [\"arn:aws:s3:::{}/*\".format(bucket)], \"Effect\": \"Allow\"},\n",
    "    ],\n",
    "}\n",
    "\n",
    "print(comprehend_s3_policy_doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attach Policy to Role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ResponseMetadata': {'RequestId': '5ba62ed9-a914-4655-ba91-0158b126e274', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '5ba62ed9-a914-4655-ba91-0158b126e274', 'content-type': 'text/xml', 'content-length': '206', 'date': 'Thu, 15 Feb 2024 23:28:29 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "response = iam.put_role_policy(\n",
    "    RoleName=iam_comprehend_role_name,\n",
    "    PolicyName=\"DSOAWS_ComprehendPolicyToS3\",\n",
    "    PolicyDocument=json.dumps(comprehend_s3_policy_doc),\n",
    ")\n",
    "\n",
    "print(response)\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/models/comprehend/output\n"
     ]
    }
   ],
   "source": [
    "prefix = \"models\"\n",
    "\n",
    "s3_output_job = \"s3://{}/{}/{}\".format(bucket, prefix, \"comprehend/output\")\n",
    "print(s3_output_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam_role_comprehend_arn = iam_role_comprehend[\"Role\"][\"Arn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon-Customer-Reviews-Classifier-1708039740\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import time\n",
    "\n",
    "timestamp = str(datetime.datetime.now().strftime(\"%s\"))\n",
    "\n",
    "comprehend_training_job_name = \"Amazon-Customer-Reviews-Classifier-{}\".format(timestamp)\n",
    "\n",
    "print(comprehend_training_job_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_job = comprehend.create_document_classifier(\n",
    "    DocumentClassifierName=comprehend_training_job_name,\n",
    "    DataAccessRoleArn=iam_role_comprehend_arn,\n",
    "    InputDataConfig={\"S3Uri\": comprehend_train_s3_uri},\n",
    "    OutputDataConfig={\"S3Uri\": s3_output_job},\n",
    "    LanguageCode=\"en\",\n",
    ")\n",
    "\n",
    "time.sleep(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:comprehend:us-east-1:211125778552:document-classifier/Amazon-Customer-Reviews-Classifier-1708039740\n"
     ]
    }
   ],
   "source": [
    "comprehend_training_job_arn = training_job[\"DocumentClassifierArn\"]\n",
    "\n",
    "print(comprehend_training_job_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/comprehend/v2/home?region=us-east-1#classifier-details/arn:aws:comprehend:us-east-1:211125778552:document-classifier/Amazon-Customer-Reviews-Classifier-1708039740\">Comprehend Training Job</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/comprehend/v2/home?region={}#classifier-details/{}\">Comprehend Training Job</a></b>'.format(\n",
    "            region, comprehend_training_job_arn\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This Next Cell Will Take Some Time\n",
    "# _Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: SUBMITTED\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINING\n",
      "Custom classifier: TRAINED\n",
      "\n",
      "Status TRAINED\n",
      "\n",
      "{'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:211125778552:document-classifier/Amazon-Customer-Reviews-Classifier-1708039740', 'LanguageCode': 'en', 'Status': 'TRAINED', 'SubmitTime': datetime.datetime(2024, 2, 15, 23, 29, 0, 280000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 2, 16, 0, 7, 58, 325000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2024, 2, 15, 23, 33, 26, 926000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 2, 16, 0, 6, 31, 808000, tzinfo=tzlocal()), 'InputDataConfig': {'DataFormat': 'COMPREHEND_CSV', 'S3Uri': 's3://sagemaker-us-east-1-211125778552/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv'}, 'OutputDataConfig': {'S3Uri': 's3://sagemaker-us-east-1-211125778552/models/comprehend/output/211125778552-CLR-5615bca1c68c5c1c05bb416ca7baa6c1/output/output.tar.gz'}, 'ClassifierMetadata': {'NumberOfLabels': 5, 'NumberOfTrainedDocuments': 810, 'NumberOfTestDocuments': 90, 'EvaluationMetrics': {'Accuracy': 0.4444, 'Precision': 0.5078, 'Recall': 0.4456, 'F1Score': 0.4307, 'MicroPrecision': 0.4444, 'MicroRecall': 0.4444, 'MicroF1Score': 0.4444, 'HammingLoss': 0.5556}}, 'DataAccessRoleArn': 'arn:aws:iam::211125778552:role/DSOAWS_Comprehend', 'Mode': 'MULTI_CLASS'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "max_time = time.time() + 3 * 60 * 60  # 3 hours\n",
    "while time.time() < max_time:\n",
    "    describe_custom_classifier = comprehend.describe_document_classifier(\n",
    "        DocumentClassifierArn=comprehend_training_job_arn\n",
    "    )\n",
    "    status = describe_custom_classifier[\"DocumentClassifierProperties\"][\"Status\"]\n",
    "    print(\"Custom classifier: {}\".format(status))\n",
    "\n",
    "    if status == \"TRAINED\" or status == \"IN_ERROR\":\n",
    "        print(\"\")\n",
    "        print(\"Status {}\".format(status))\n",
    "        print(\"\")\n",
    "        print(describe_custom_classifier[\"DocumentClassifierProperties\"])\n",
    "        break\n",
    "\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# _Please Wait Until the ^^ Classifier ^^ is Trained Above._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [INFO] _Feel free to continue to the next workshop section while this notebook is running._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show Results of the Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DocumentClassifierArn': 'arn:aws:comprehend:us-east-1:211125778552:document-classifier/Amazon-Customer-Reviews-Classifier-1708039740', 'LanguageCode': 'en', 'Status': 'TRAINED', 'SubmitTime': datetime.datetime(2024, 2, 15, 23, 29, 0, 280000, tzinfo=tzlocal()), 'EndTime': datetime.datetime(2024, 2, 16, 0, 7, 58, 325000, tzinfo=tzlocal()), 'TrainingStartTime': datetime.datetime(2024, 2, 15, 23, 33, 26, 926000, tzinfo=tzlocal()), 'TrainingEndTime': datetime.datetime(2024, 2, 16, 0, 6, 31, 808000, tzinfo=tzlocal()), 'InputDataConfig': {'DataFormat': 'COMPREHEND_CSV', 'S3Uri': 's3://sagemaker-us-east-1-211125778552/data/amazon_reviews_us_Digital_Software_v1_00_comprehend.csv'}, 'OutputDataConfig': {'S3Uri': 's3://sagemaker-us-east-1-211125778552/models/comprehend/output/211125778552-CLR-5615bca1c68c5c1c05bb416ca7baa6c1/output/output.tar.gz'}, 'ClassifierMetadata': {'NumberOfLabels': 5, 'NumberOfTrainedDocuments': 810, 'NumberOfTestDocuments': 90, 'EvaluationMetrics': {'Accuracy': 0.4444, 'Precision': 0.5078, 'Recall': 0.4456, 'F1Score': 0.4307, 'MicroPrecision': 0.4444, 'MicroRecall': 0.4444, 'MicroF1Score': 0.4444, 'HammingLoss': 0.5556}}, 'DataAccessRoleArn': 'arn:aws:iam::211125778552:role/DSOAWS_Comprehend', 'Mode': 'MULTI_CLASS'}\n"
     ]
    }
   ],
   "source": [
    "print(describe_custom_classifier[\"DocumentClassifierProperties\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:comprehend:us-east-1:211125778552:document-classifier/Amazon-Customer-Reviews-Classifier-1708039740\n"
     ]
    }
   ],
   "source": [
    "model_arn = describe_custom_classifier[\"DocumentClassifierProperties\"][\"DocumentClassifierArn\"]\n",
    "print(model_arn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-211125778552/models/comprehend/output/211125778552-CLR-5615bca1c68c5c1c05bb416ca7baa6c1/output/output.tar.gz\n",
      "models/comprehend/output/211125778552-CLR-5615bca1c68c5c1c05bb416ca7baa6c1/output/output.tar.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Retrieve the S3URI from the model output and create jobkey variable.\n",
    "job_output = describe_custom_classifier[\"DocumentClassifierProperties\"][\"OutputDataConfig\"][\"S3Uri\"]\n",
    "print(job_output)\n",
    "\n",
    "path_prefix = \"s3://{}/\".format(bucket)\n",
    "\n",
    "job_key = os.path.relpath(job_output, path_prefix)\n",
    "\n",
    "print(job_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Model Artifacts including Training Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sagemaker-user/.conda/envs/data_science_on_aws/lib/python3.7/site-packages/boto3/compat.py:82: PythonDeprecationWarning: Boto3 will no longer support Python 3.7 starting December 13, 2023. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.8 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "\n",
    "s3.Bucket(bucket).download_file(job_key, \"./output.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "output/\n",
      "tar: Ignoring unknown extended header keyword 'LIBARCHIVE.creationtime'\n",
      "output/confusion_matrix.json\n"
     ]
    }
   ],
   "source": [
    "# Unpack the gzip file\n",
    "!tar xvzf ./output.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"confusion_matrix\": [\n",
      "    [\n",
      "      7,\n",
      "      10,\n",
      "      2,\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      2,\n",
      "      15,\n",
      "      0,\n",
      "      1,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      1,\n",
      "      13,\n",
      "      2,\n",
      "      2,\n",
      "      0\n",
      "    ],\n",
      "    [\n",
      "      0,\n",
      "      4,\n",
      "      3,\n",
      "      8,\n",
      "      3\n",
      "    ],\n",
      "    [\n",
      "      0,\n",
      "      4,\n",
      "      0,\n",
      "      5,\n",
      "      8\n",
      "    ]\n",
      "  ],\n",
      "  \"labels\": [\n",
      "    \"1\",\n",
      "    \"2\",\n",
      "    \"3\",\n",
      "    \"4\",\n",
      "    \"5\"\n",
      "  ],\n",
      "  \"type\": \"multi_class\",\n",
      "  \"all_labels\": [\n",
      "    \"1\",\n",
      "    \"2\",\n",
      "    \"3\",\n",
      "    \"4\",\n",
      "    \"5\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./output/confusion_matrix.json\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "print(json.dumps(data, indent=2, default=str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "<tr><td>        </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\"> 2</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">4</td><td style=\"text-align: right;\">5</td><td>(Predicted)</td></tr>\n",
       "<tr><td>1       </td><td style=\"text-align: right;\">7</td><td style=\"text-align: right;\">10</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">0</td><td>           </td></tr>\n",
       "<tr><td>2       </td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">15</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">0</td><td>           </td></tr>\n",
       "<tr><td>3       </td><td style=\"text-align: right;\">1</td><td style=\"text-align: right;\">13</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">2</td><td style=\"text-align: right;\">0</td><td>           </td></tr>\n",
       "<tr><td>4       </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> 4</td><td style=\"text-align: right;\">3</td><td style=\"text-align: right;\">8</td><td style=\"text-align: right;\">3</td><td>           </td></tr>\n",
       "<tr><td>5       </td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\"> 4</td><td style=\"text-align: right;\">0</td><td style=\"text-align: right;\">5</td><td style=\"text-align: right;\">8</td><td>           </td></tr>\n",
       "<tr><td>(Actual)</td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\">  </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\"> </td><td style=\"text-align: right;\"> </td><td>           </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import HTML, display\n",
    "import tabulate\n",
    "\n",
    "table = [\n",
    "    [\"\", \"1\", \"2\", \"3\", \"4\", \"5\", \"(Predicted)\"],\n",
    "    [\n",
    "        \"1\",\n",
    "        data[\"confusion_matrix\"][0][0],\n",
    "        data[\"confusion_matrix\"][0][1],\n",
    "        data[\"confusion_matrix\"][0][2],\n",
    "        data[\"confusion_matrix\"][0][3],\n",
    "        data[\"confusion_matrix\"][0][4],\n",
    "    ],\n",
    "    [\n",
    "        \"2\",\n",
    "        data[\"confusion_matrix\"][1][0],\n",
    "        data[\"confusion_matrix\"][1][1],\n",
    "        data[\"confusion_matrix\"][1][2],\n",
    "        data[\"confusion_matrix\"][1][3],\n",
    "        data[\"confusion_matrix\"][1][4],\n",
    "    ],\n",
    "    [\n",
    "        \"3\",\n",
    "        data[\"confusion_matrix\"][2][0],\n",
    "        data[\"confusion_matrix\"][2][1],\n",
    "        data[\"confusion_matrix\"][2][2],\n",
    "        data[\"confusion_matrix\"][2][3],\n",
    "        data[\"confusion_matrix\"][2][4],\n",
    "    ],\n",
    "    [\n",
    "        \"4\",\n",
    "        data[\"confusion_matrix\"][3][0],\n",
    "        data[\"confusion_matrix\"][3][1],\n",
    "        data[\"confusion_matrix\"][3][2],\n",
    "        data[\"confusion_matrix\"][3][3],\n",
    "        data[\"confusion_matrix\"][3][4],\n",
    "    ],\n",
    "    [\n",
    "        \"5\",\n",
    "        data[\"confusion_matrix\"][4][0],\n",
    "        data[\"confusion_matrix\"][4][1],\n",
    "        data[\"confusion_matrix\"][4][2],\n",
    "        data[\"confusion_matrix\"][4][3],\n",
    "        data[\"confusion_matrix\"][4][4],\n",
    "    ],\n",
    "    [\"(Actual)\"],\n",
    "]\n",
    "display(HTML(tabulate.tabulate(table, tablefmt=\"html\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime, sleep\n",
    "\n",
    "timestamp_suffix = strftime(\"%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "comprehend_endpoint_name = \"comprehend-inference-ep-\" + timestamp_suffix\n",
    "\n",
    "inference_endpoint_response = comprehend.create_endpoint(\n",
    "    EndpointName=comprehend_endpoint_name, ModelArn=model_arn, DesiredInferenceUnits=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:comprehend:us-east-1:211125778552:document-classifier-endpoint/comprehend-inference-ep-16-00-08-02\n"
     ]
    }
   ],
   "source": [
    "comprehend_endpoint_arn = inference_endpoint_response[\"EndpointArn\"]\n",
    "print(comprehend_endpoint_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass Variables to the Next Notebook(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'comprehend_training_job_arn' (str)\n"
     ]
    }
   ],
   "source": [
    "%store comprehend_training_job_arn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'comprehend_endpoint_arn' (str)\n"
     ]
    }
   ],
   "source": [
    "%store comprehend_endpoint_arn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Release Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
       "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
       "        \n",
       "<script>\n",
       "try {\n",
       "    els = document.getElementsByClassName(\"sm-command-button\");\n",
       "    els[0].click();\n",
       "}\n",
       "catch(err) {\n",
       "    // NoOp\n",
       "}    \n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "\n",
    "<p><b>Shutting down your kernel for this notebook to release resources.</b></p>\n",
    "<button class=\"sm-command-button\" data-commandlinker-command=\"kernelmenu:shutdown\" style=\"display:none;\">Shutdown Kernel</button>\n",
    "        \n",
    "<script>\n",
    "try {\n",
    "    els = document.getElementsByClassName(\"sm-command-button\");\n",
    "    els[0].click();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "\ntry {\n    Jupyter.notebook.save_checkpoint();\n    Jupyter.notebook.session.delete();\n}\ncatch(err) {\n    // NoOp\n}\n",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "\n",
    "try {\n",
    "    Jupyter.notebook.save_checkpoint();\n",
    "    Jupyter.notebook.session.delete();\n",
    "}\n",
    "catch(err) {\n",
    "    // NoOp\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "data_science_on_aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
